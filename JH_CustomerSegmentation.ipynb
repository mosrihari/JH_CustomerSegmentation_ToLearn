{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JH_CustomerSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EUAP7vWlWo_W"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO2mTbJIOHtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3a42fbdf-dd4d-43c3-c6b4-c8cc9c75aa64"
      },
      "source": [
        "#!pip uninstall featuretools\n",
        "#!pip install featuretools[complete]\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold,KFold"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26E2E38LOmKb",
        "colab_type": "text"
      },
      "source": [
        "## Reading datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfCXOyOYPMzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/CustomerSegmentation_JH/Train_aBjfeNk.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/CustomerSegmentation_JH/Test_LqhgPWU.csv\")  \n",
        "submission = pd.read_csv(\"/content/drive/My Drive/CustomerSegmentation_JH/sample_submission_wyi0h0z.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A068VkA-hodH",
        "colab_type": "text"
      },
      "source": [
        "## Helpful Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYPB3N7fhql4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_score(m):\n",
        "  all_metrics = [m.score(X_train,y_train),m.score(X_valid,y_valid)]\n",
        "  if hasattr(m,\"oob_score\"):\n",
        "    all_metrics.append(m.oob_score)\n",
        "  return all_metrics "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvYPz3WcPYHf",
        "colab_type": "text"
      },
      "source": [
        "## Analysing datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axJGqnVAPbxh",
        "colab_type": "text"
      },
      "source": [
        "### Checking NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73TmxD3jPgTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0b624e3c-6846-4d0f-bf33-79389a32dd7c"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Ever_Married</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Var_1</th>\n",
              "      <th>Segmentation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462809</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>462643</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>38</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Average</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>466315</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>67</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>461735</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>67</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Lawyer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>High</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462669</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>40</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>High</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Gender Ever_Married  ...  Family_Size  Var_1 Segmentation\n",
              "0  462809    Male           No  ...          4.0  Cat_4            D\n",
              "1  462643  Female          Yes  ...          3.0  Cat_4            A\n",
              "2  466315  Female          Yes  ...          1.0  Cat_6            B\n",
              "3  461735    Male          Yes  ...          2.0  Cat_6            B\n",
              "4  462669  Female          Yes  ...          6.0  Cat_6            A\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAUYhXmzPiNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3b56de96-c381-430e-c878-30610345e08e"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Ever_Married</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Var_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>458989</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>36</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>458994</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>37</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Average</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>458996</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>69</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>459000</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>59</td>\n",
              "      <td>No</td>\n",
              "      <td>Executive</td>\n",
              "      <td>11.0</td>\n",
              "      <td>High</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>459001</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>19</td>\n",
              "      <td>No</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Low</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Gender Ever_Married  ...  Spending_Score Family_Size  Var_1\n",
              "0  458989  Female          Yes  ...             Low         1.0  Cat_6\n",
              "1  458994    Male          Yes  ...         Average         4.0  Cat_6\n",
              "2  458996  Female          Yes  ...             Low         1.0  Cat_6\n",
              "3  459000    Male          Yes  ...            High         2.0  Cat_6\n",
              "4  459001  Female           No  ...             Low         4.0  Cat_6\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpQud24_Pj-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "e29cf728-c780-490b-b864-5cadd7c476a5"
      },
      "source": [
        "print(train.isnull().sum())\n",
        "print(\"--------------------\")\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID                   0\n",
            "Gender               0\n",
            "Ever_Married       140\n",
            "Age                  0\n",
            "Graduated           78\n",
            "Profession         124\n",
            "Work_Experience    829\n",
            "Spending_Score       0\n",
            "Family_Size        335\n",
            "Var_1               76\n",
            "Segmentation         0\n",
            "dtype: int64\n",
            "--------------------\n",
            "ID                   0\n",
            "Gender               0\n",
            "Ever_Married        50\n",
            "Age                  0\n",
            "Graduated           24\n",
            "Profession          38\n",
            "Work_Experience    269\n",
            "Spending_Score       0\n",
            "Family_Size        113\n",
            "Var_1               32\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMihEtVMPlod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combined_df(train,test):\n",
        "  train['is_train'] = 1\n",
        "  test['is_train'] = 0\n",
        "  return pd.concat([train,test],axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy8NGn_RQ_GR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined = combined_df(train,test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbXwC-5VRLDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d89145a1-b732-4249-b799-b92fd8145ae0"
      },
      "source": [
        "combined.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                    0\n",
              "Gender                0\n",
              "Ever_Married        190\n",
              "Age                   0\n",
              "Graduated           102\n",
              "Profession          162\n",
              "Work_Experience    1098\n",
              "Spending_Score        0\n",
              "Family_Size         448\n",
              "Var_1               108\n",
              "Segmentation       2627\n",
              "is_train              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZnJnzGsRBlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## METHOD TO FILL NULL VALUES\n",
        "## I could see some of the customers whose age is 50+ also has Graduated as No \n",
        "## It is difficult to fill the graduated as yes or no based on age. Hence it is better to fill the mode\n",
        "## Ever married and family size go hand in hand with each other. But the customer can live with parents as well\n",
        "## Work experience also has anamoly with 0 when the age is 30+."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xO-bSVJRoU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ca07945a-f688-48fc-e386-22eab9bda408"
      },
      "source": [
        "combined['Graduated'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yes    6570\n",
              "No     4023\n",
              "Name: Graduated, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzJ2B8SqRt9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "b47b3207-1505-4b92-efba-fa956ff32648"
      },
      "source": [
        "plt.hist(combined[combined['Ever_Married'] == \"Yes\"]['Age'])\n",
        "## It is safe to assume that till 25 the chances of getting married is less. Hence we can conditionally fill the values\n",
        "## When the age < 25, Ever married is No else Yes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  98.,  461.,  958., 1095., 1219.,  657.,  565.,  509.,  266.,\n",
              "         335.]),\n",
              " array([18. , 25.1, 32.2, 39.3, 46.4, 53.5, 60.6, 67.7, 74.8, 81.9, 89. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSgYl88sR98G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9def70ba-5df5-4a0e-b5af-6c66b2667975"
      },
      "source": [
        "plt.hist(combined[combined['Graduated'] == \"Yes\"]['Age'])\n",
        "## It is safe to assume that till 25 the chances of getting graudated is less. Hence we can conditionally fill the values\n",
        "## When the age < 25, Graduated is No else Yes"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 148., 1018., 1275., 1249., 1154.,  567.,  453.,  341.,  160.,\n",
              "         205.]),\n",
              " array([18. , 25.1, 32.2, 39.3, 46.4, 53.5, 60.6, 67.7, 74.8, 81.9, 89. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSm-AaUtS2f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conditions = [combined['Age'] < 25, combined['Age'] >= 25]\n",
        "values = ['No','Yes']\n",
        "\n",
        "# apply logic where ever_married is null\n",
        "combined['Ever_Married'] = np.where(combined['Ever_Married'].isnull(),\n",
        "                              np.select(conditions, values),\n",
        "                              combined['Ever_Married'])\n",
        "combined['Graduated'] = np.where(combined['Graduated'].isnull(),\n",
        "                              np.select(conditions, values),\n",
        "                              combined['Graduated'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlqSGrRAUYqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "596cbf70-1bfb-4cd0-cb24-842319c604a9"
      },
      "source": [
        "combined['Profession'].value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Artist           3318\n",
              "Healthcare       1750\n",
              "Entertainment    1250\n",
              "Engineer          935\n",
              "Doctor            930\n",
              "Lawyer            844\n",
              "Executive         775\n",
              "Marketing         403\n",
              "Homemaker         328\n",
              "Name: Profession, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYh6OuIZT3pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We may not know the Profession at all. Lets fill \"others\"\n",
        "combined['Profession'].fillna(\"Others\",inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUBZz5H_T5So",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6313a67a-ce05-4cb7-84a1-e66a4fc62d56"
      },
      "source": [
        "combined.isnull().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                    0\n",
              "Gender                0\n",
              "Ever_Married          0\n",
              "Age                   0\n",
              "Graduated             0\n",
              "Profession            0\n",
              "Work_Experience    1098\n",
              "Spending_Score        0\n",
              "Family_Size         448\n",
              "Var_1               108\n",
              "Segmentation       2627\n",
              "is_train              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GIBiemwU8Bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0fc5f77d-ad13-4f44-e143-af4aa56515e3"
      },
      "source": [
        "sns.boxplot(combined['Work_Experience'],combined['Age'])\n",
        "## Right from having 0 work experience till 14 years of experience, the median age always lies close to 35-45\n",
        "## Also When the work experience is more, the bottom whisker also touches 20 age which is a serious anamoly\n",
        "## Hence we can fill mode value"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5c00026e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GB_gFV8VvhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9ebef2bc-3faa-4c83-c985-c7dd0d9bf589"
      },
      "source": [
        "combined['Work_Experience'].mode()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgYIum1vUT0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['Work_Experience'].fillna(1,inplace=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F-MS1hWUpND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b8d200e0-4a84-4c6b-f40b-56246c5fc25b"
      },
      "source": [
        "combined.isnull().sum()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                    0\n",
              "Gender                0\n",
              "Ever_Married          0\n",
              "Age                   0\n",
              "Graduated             0\n",
              "Profession            0\n",
              "Work_Experience       0\n",
              "Spending_Score        0\n",
              "Family_Size         448\n",
              "Var_1               108\n",
              "Segmentation       2627\n",
              "is_train              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-f_K55GVoSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['Family_Size'].value_counts()\n",
        "combined['Family_Size'].fillna(2,inplace=True) ## Filling the mode"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YsOAA3AV5kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "044aab24-6902-4ca3-8753-388532fb0433"
      },
      "source": [
        "combined.isnull().sum()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                    0\n",
              "Gender                0\n",
              "Ever_Married          0\n",
              "Age                   0\n",
              "Graduated             0\n",
              "Profession            0\n",
              "Work_Experience       0\n",
              "Spending_Score        0\n",
              "Family_Size           0\n",
              "Var_1               108\n",
              "Segmentation       2627\n",
              "is_train              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs1pkQinWH2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['Var_1'].value_counts()\n",
        "## Lets fill this anonymised category as \"Cat_Unknown\" as there is only 108 null values\n",
        "combined['Var_1'].fillna(\"Cat_Unknown\",inplace=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVR36pnnWXbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3bfbe8f1-2eb4-47d5-a485-48b8b33b7d51"
      },
      "source": [
        "combined.isnull().sum()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                    0\n",
              "Gender                0\n",
              "Ever_Married          0\n",
              "Age                   0\n",
              "Graduated             0\n",
              "Profession            0\n",
              "Work_Experience       0\n",
              "Spending_Score        0\n",
              "Family_Size           0\n",
              "Var_1                 0\n",
              "Segmentation       2627\n",
              "is_train              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUAP7vWlWo_W",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering FT Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwnmtj1nXDkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import featuretools as ft\n",
        "import featuretools.variable_types as vtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgjQZkzfd6fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['index'] = np.arange(len(combined))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21t6EeJRXD5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "segments = combined['Segmentation']\n",
        "is_train = combined['is_train']\n",
        "combined.drop(['Segmentation','is_train'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3_u4guKXVDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = ft.EntitySet(id = 'customer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERh7Qkyubf-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variable_types = { 'Gender': vtypes.Categorical,\n",
        "                  'Ever_Married': vtypes.Categorical,\n",
        "                  'Graduated': vtypes.Categorical,\n",
        "                  'Profession': vtypes.Categorical,\n",
        "                  'Spending_Score': vtypes.Categorical,\n",
        "                  'Var_1': vtypes.Categorical,\n",
        "                  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGzkSvMBdNx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f4ae71f2-9a97-4f1c-bca2-62c4c574ee5a"
      },
      "source": [
        "combined.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Ever_Married</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Var_1</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462809</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>462643</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>38</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Average</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>466315</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>67</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>461735</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>67</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Lawyer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>High</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462669</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>40</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>1.0</td>\n",
              "      <td>High</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Gender Ever_Married  Age  ... Spending_Score Family_Size  Var_1 index\n",
              "0  462809    Male           No   22  ...            Low         4.0  Cat_4     0\n",
              "1  462643  Female          Yes   38  ...        Average         3.0  Cat_4     1\n",
              "2  466315  Female          Yes   67  ...            Low         1.0  Cat_6     2\n",
              "3  461735    Male          Yes   67  ...           High         2.0  Cat_6     3\n",
              "4  462669  Female          Yes   40  ...           High         6.0  Cat_6     4\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN295WTXcVGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e6125c99-78a6-486e-e69e-213200c39d28"
      },
      "source": [
        "es.entity_from_dataframe(entity_id = 'data', dataframe = combined, \n",
        "                        index = 'index',variable_types=variable_types)\n",
        "feature_matrix, feature_list = ft.dfs(entityset = es, target_entity = 'data',max_depth=3,\n",
        "                                      agg_primitives=[\"mode\"],\n",
        "                                      )\n",
        "main2=feature_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:\n",
            "  agg_primitives: ['mode']\n",
            "This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.\n",
            "  warnings.warn(warning_msg, UnusedPrimitiveWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMfJxRw-dIX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "8c770a8f-392a-4533-e1ca-39f4fbd65fa5"
      },
      "source": [
        "main2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Ever_Married</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Var_1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462809</td>\n",
              "      <td>22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Low</td>\n",
              "      <td>Cat_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>462643</td>\n",
              "      <td>38</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Average</td>\n",
              "      <td>Cat_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>466315</td>\n",
              "      <td>67</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Low</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>461735</td>\n",
              "      <td>67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Lawyer</td>\n",
              "      <td>High</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462669</td>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>High</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10690</th>\n",
              "      <td>467954</td>\n",
              "      <td>29</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Low</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10691</th>\n",
              "      <td>467958</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>Low</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10692</th>\n",
              "      <td>467960</td>\n",
              "      <td>53</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Low</td>\n",
              "      <td>Cat_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10693</th>\n",
              "      <td>467961</td>\n",
              "      <td>47</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Executive</td>\n",
              "      <td>High</td>\n",
              "      <td>Cat_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10694</th>\n",
              "      <td>467968</td>\n",
              "      <td>43</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Low</td>\n",
              "      <td>Cat_7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10695 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID  Age  Work_Experience  ...     Profession Spending_Score  Var_1\n",
              "index                                ...                                     \n",
              "0      462809   22              1.0  ...     Healthcare            Low  Cat_4\n",
              "1      462643   38              1.0  ...       Engineer        Average  Cat_4\n",
              "2      466315   67              1.0  ...       Engineer            Low  Cat_6\n",
              "3      461735   67              0.0  ...         Lawyer           High  Cat_6\n",
              "4      462669   40              1.0  ...  Entertainment           High  Cat_6\n",
              "...       ...  ...              ...  ...            ...            ...    ...\n",
              "10690  467954   29              9.0  ...     Healthcare            Low  Cat_6\n",
              "10691  467958   35              1.0  ...         Doctor            Low  Cat_6\n",
              "10692  467960   53              1.0  ...  Entertainment            Low  Cat_6\n",
              "10693  467961   47              1.0  ...      Executive           High  Cat_4\n",
              "10694  467968   43              9.0  ...     Healthcare            Low  Cat_7\n",
              "\n",
              "[10695 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rMV9oHAeSvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7ae3d581-1521-463e-89be-27d8be951a2c"
      },
      "source": [
        "feature_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Feature: ID>,\n",
              " <Feature: Age>,\n",
              " <Feature: Work_Experience>,\n",
              " <Feature: Family_Size>,\n",
              " <Feature: Gender>,\n",
              " <Feature: Ever_Married>,\n",
              " <Feature: Graduated>,\n",
              " <Feature: Profession>,\n",
              " <Feature: Spending_Score>,\n",
              " <Feature: Var_1>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nb7SZPNzCDb",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMNS6wnzGT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combined['Age_qcut'] = pd.qcut(combined['Age'], 6)\n",
        "# combined['Work_Experience_qcut'] = pd.qcut(combined['Work_Experience'], 3,duplicates=\"drop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-soOf-ozxl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['Work_start_age'] = combined['Age'] - combined['Work_Experience']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsjpbHqs7Mn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['Family_Size_Excl_customer'] = combined['Family_Size'] - 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdLTJXM2_pzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = pd.cut(combined['Age'],11)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeznS1t_B-Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.categories = [1,2,3,4,5,6,7,8,9,10,11]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR5S-WW7CO43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['age_category'] = x"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il1WOaqbCvek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined['age_category'] = combined['age_category'].cat.codes"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W38Q5c0FvXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "38181dcf-b702-40b8-ff0d-0aae234a162d"
      },
      "source": [
        "combined.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Ever_Married</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Var_1</th>\n",
              "      <th>Segmentation</th>\n",
              "      <th>is_train</th>\n",
              "      <th>Work_start_age</th>\n",
              "      <th>Family_Size_Excl_customer</th>\n",
              "      <th>age_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462809</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>462643</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>38</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Average</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>466315</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>67</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>461735</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>67</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Lawyer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>High</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462669</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>40</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>1.0</td>\n",
              "      <td>High</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Gender  ... Family_Size_Excl_customer  age_category\n",
              "0  462809    Male  ...                       3.0             0\n",
              "1  462643  Female  ...                       2.0             3\n",
              "2  466315  Female  ...                       0.0             7\n",
              "3  461735    Male  ...                       1.0             7\n",
              "4  462669  Female  ...                       5.0             3\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSINeOzQFwE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaPXaJ9ieaKL",
        "colab_type": "text"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqiKx3RWgSqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe_combined = pd.get_dummies(combined,columns=['Gender','Ever_Married','Profession','Var_1'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrKdb8q7g46Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "8a8dbf96-a775-4828-befd-87413c66cc3f"
      },
      "source": [
        "combined['Spending_Score'].value_counts()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Low        6494\n",
              "Average    2599\n",
              "High       1602\n",
              "Name: Spending_Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2bopBj7gwbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Graduate_Mapping = {\"Yes\":1,\"No\":0}\n",
        "Spending_Mapping = {\"Low\":0,'Average':1,'High':2}"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOeCc-0ThD5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe_combined['Graduated'] = ohe_combined['Graduated'].map(Graduate_Mapping)\n",
        "ohe_combined['Spending_Score'] = ohe_combined['Spending_Score'].map(Spending_Mapping)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKeDwirQAO29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EA8-Cgdh7er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(df,features):\n",
        "    result = df.copy()\n",
        "    max_value = df[features].max()\n",
        "    min_value = df[features].min()\n",
        "    features_normalized = features +\"_Normalized\"\n",
        "    result[features_normalized] = (df[features] - min_value) / (max_value - min_value)\n",
        "    return result\n",
        "\n",
        "ohe_combined = normalize(ohe_combined,\"Age\")\n",
        "ohe_combined = normalize(ohe_combined,\"Work_Experience\")\n",
        "ohe_combined = normalize(ohe_combined,\"Family_Size\")\n",
        "ohe_combined = normalize(ohe_combined,\"Work_start_age\")\n",
        "ohe_combined = normalize(ohe_combined,\"Family_Size_Excl_customer\")"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s5F0KODiqZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "dc7bf56b-7432-4bcf-83ce-dc730743c99d"
      },
      "source": [
        "ohe_combined.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Segmentation</th>\n",
              "      <th>is_train</th>\n",
              "      <th>Work_start_age</th>\n",
              "      <th>Family_Size_Excl_customer</th>\n",
              "      <th>age_category</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Ever_Married_No</th>\n",
              "      <th>Ever_Married_Yes</th>\n",
              "      <th>Profession_Artist</th>\n",
              "      <th>Profession_Doctor</th>\n",
              "      <th>Profession_Engineer</th>\n",
              "      <th>Profession_Entertainment</th>\n",
              "      <th>Profession_Executive</th>\n",
              "      <th>Profession_Healthcare</th>\n",
              "      <th>Profession_Homemaker</th>\n",
              "      <th>Profession_Lawyer</th>\n",
              "      <th>Profession_Marketing</th>\n",
              "      <th>Profession_Others</th>\n",
              "      <th>Var_1_Cat_1</th>\n",
              "      <th>Var_1_Cat_2</th>\n",
              "      <th>Var_1_Cat_3</th>\n",
              "      <th>Var_1_Cat_4</th>\n",
              "      <th>Var_1_Cat_5</th>\n",
              "      <th>Var_1_Cat_6</th>\n",
              "      <th>Var_1_Cat_7</th>\n",
              "      <th>Var_1_Cat_Unknown</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Work_Experience_Normalized</th>\n",
              "      <th>Family_Size_Normalized</th>\n",
              "      <th>Work_start_age_Normalized</th>\n",
              "      <th>Family_Size_Excl_customer_Normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462809</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>462643</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.281690</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>466315</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>461735</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462669</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Age  ...  Work_start_age_Normalized  Family_Size_Excl_customer_Normalized\n",
              "0  462809   22  ...                   0.200000                                 0.375\n",
              "1  462643   38  ...                   0.388235                                 0.250\n",
              "2  466315   67  ...                   0.729412                                 0.000\n",
              "3  461735   67  ...                   0.741176                                 0.125\n",
              "4  462669   40  ...                   0.411765                                 0.625\n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcp-6bCR2Weq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe_combined['Spend_Family'] = ohe_combined['Spending_Score'] * ohe_combined['Family_Size_Excl_customer_Normalized']"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41sEzPbS4ZVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe_combined['Work_Spend_Score'] = ohe_combined['Spending_Score'] * ohe_combined['Work_Experience_Normalized']"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nZSf5F35Xhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "131057df-9d02-4d13-8c30-8c5fa89c9581"
      },
      "source": [
        "ohe_combined"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Segmentation</th>\n",
              "      <th>is_train</th>\n",
              "      <th>Work_start_age</th>\n",
              "      <th>Family_Size_Excl_customer</th>\n",
              "      <th>age_category</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Ever_Married_No</th>\n",
              "      <th>Ever_Married_Yes</th>\n",
              "      <th>Profession_Artist</th>\n",
              "      <th>Profession_Doctor</th>\n",
              "      <th>Profession_Engineer</th>\n",
              "      <th>Profession_Entertainment</th>\n",
              "      <th>Profession_Executive</th>\n",
              "      <th>Profession_Healthcare</th>\n",
              "      <th>Profession_Homemaker</th>\n",
              "      <th>Profession_Lawyer</th>\n",
              "      <th>Profession_Marketing</th>\n",
              "      <th>Profession_Others</th>\n",
              "      <th>Var_1_Cat_1</th>\n",
              "      <th>Var_1_Cat_2</th>\n",
              "      <th>Var_1_Cat_3</th>\n",
              "      <th>Var_1_Cat_4</th>\n",
              "      <th>Var_1_Cat_5</th>\n",
              "      <th>Var_1_Cat_6</th>\n",
              "      <th>Var_1_Cat_7</th>\n",
              "      <th>Var_1_Cat_Unknown</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Work_Experience_Normalized</th>\n",
              "      <th>Family_Size_Normalized</th>\n",
              "      <th>Work_start_age_Normalized</th>\n",
              "      <th>Family_Size_Excl_customer_Normalized</th>\n",
              "      <th>Spend_Family</th>\n",
              "      <th>Work_Spend_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462809</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>462643</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.281690</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>466315</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>461735</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462669</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.625</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2622</th>\n",
              "      <td>467954</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.154930</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2623</th>\n",
              "      <td>467958</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.239437</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2624</th>\n",
              "      <td>467960</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>467961</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2626</th>\n",
              "      <td>467968</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.352113</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10695 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  Age  ...  Spend_Family  Work_Spend_Score\n",
              "0     462809   22  ...          0.00          0.000000\n",
              "1     462643   38  ...          0.25          0.071429\n",
              "2     466315   67  ...          0.00          0.000000\n",
              "3     461735   67  ...          0.25          0.000000\n",
              "4     462669   40  ...          1.25          0.142857\n",
              "...      ...  ...  ...           ...               ...\n",
              "2622  467954   29  ...          0.00          0.000000\n",
              "2623  467958   35  ...          0.00          0.000000\n",
              "2624  467960   53  ...          0.00          0.000000\n",
              "2625  467961   47  ...          1.00          0.142857\n",
              "2626  467968   43  ...          0.00          0.000000\n",
              "\n",
              "[10695 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzM9ohpsIFoD",
        "colab_type": "text"
      },
      "source": [
        "## Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXTsWGybfuSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = ohe_combined[combined['is_train'] == 1]\n",
        "test_df = ohe_combined[combined['is_train'] == 0]"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4PVlWWOf7Eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "55b92215-a0f3-48cd-d748-0fb054699f66"
      },
      "source": [
        "train_df.drop(\"is_train\",axis=1,inplace=True)\n",
        "test_df.drop([\"is_train\",\"Segmentation\"],axis=1,inplace=True)\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDCzXb8tgDii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "49a86be9-59c9-443d-d8f6-a72bf3609c50"
      },
      "source": [
        "train_df.drop(\"ID\",axis=1,inplace=True)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FF0LgAfjQ5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "b891b75a-501e-4096-c54c-e335a87fbdb0"
      },
      "source": [
        "train_df['Segmentation'].value_counts()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "D    2268\n",
              "A    1972\n",
              "C    1970\n",
              "B    1858\n",
              "Name: Segmentation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fjsj3GZsjYyh",
        "colab": {}
      },
      "source": [
        "Segmentation_Mapping = {\"A\":0,'B':1,'C':2,'D':3}"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IDvD1JFojYyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "6759fd46-81b9-4076-9aaa-377d6e574636"
      },
      "source": [
        "train_df['Segmentation'] = train_df['Segmentation'].map(Segmentation_Mapping)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFQa27vB_OdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "679e5b25-6702-41dd-cb22-ee159434557c"
      },
      "source": [
        "train_df.columns"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Graduated', 'Work_Experience', 'Spending_Score', 'Family_Size',\n",
              "       'Segmentation', 'Work_start_age', 'Family_Size_Excl_customer',\n",
              "       'age_category', 'Gender_Female', 'Gender_Male', 'Ever_Married_No',\n",
              "       'Ever_Married_Yes', 'Profession_Artist', 'Profession_Doctor',\n",
              "       'Profession_Engineer', 'Profession_Entertainment',\n",
              "       'Profession_Executive', 'Profession_Healthcare', 'Profession_Homemaker',\n",
              "       'Profession_Lawyer', 'Profession_Marketing', 'Profession_Others',\n",
              "       'Var_1_Cat_1', 'Var_1_Cat_2', 'Var_1_Cat_3', 'Var_1_Cat_4',\n",
              "       'Var_1_Cat_5', 'Var_1_Cat_6', 'Var_1_Cat_7', 'Var_1_Cat_Unknown',\n",
              "       'Age_Normalized', 'Work_Experience_Normalized',\n",
              "       'Family_Size_Normalized', 'Work_start_age_Normalized',\n",
              "       'Family_Size_Excl_customer_Normalized', 'Spend_Family',\n",
              "       'Work_Spend_Score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haWIF3gvgEyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_df.drop([\"Age\",\"Work_Experience\",\"Family_Size\",\"Segmentation\",'Work_start_age', 'Family_Size_Excl_customer'],axis=1)\n",
        "y = train_df['Segmentation']"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnhmJqtJjBXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,random_state=42)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_fpz8gEvfNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbomnYXvtN1",
        "colab_type": "text"
      },
      "source": [
        "## Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D3b_Lu7vyqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f893f944-f705-4ad6-c126-19f99ba0259e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6454, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLr1Lk7nyrM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(16,input_dim=30,activation='relu'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(4,activation='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXB7rmHwbQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=100, verbose=True)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT8F072XwwUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cde8d32a-e7ee-4042-bb59-4853eb375f99"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 29us/step - loss: 1.3345 - accuracy: 0.3948\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.2059 - accuracy: 0.4678\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.1418 - accuracy: 0.4990\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1113 - accuracy: 0.5081\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0953 - accuracy: 0.5155\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0834 - accuracy: 0.5167\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0750 - accuracy: 0.5184\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0704 - accuracy: 0.5218\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0651 - accuracy: 0.5261\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0608 - accuracy: 0.5229\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0577 - accuracy: 0.5306\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0542 - accuracy: 0.5271\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0527 - accuracy: 0.5280\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0489 - accuracy: 0.5258\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0473 - accuracy: 0.5294\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0465 - accuracy: 0.5275\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0433 - accuracy: 0.5366\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0413 - accuracy: 0.5360\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0395 - accuracy: 0.5338\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0376 - accuracy: 0.5352\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0368 - accuracy: 0.5364\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0360 - accuracy: 0.5348\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0329 - accuracy: 0.5388\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0327 - accuracy: 0.5388\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0319 - accuracy: 0.5390\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0296 - accuracy: 0.5408\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0292 - accuracy: 0.5408\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0281 - accuracy: 0.5382\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0256 - accuracy: 0.5406\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0262 - accuracy: 0.5406\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0246 - accuracy: 0.5385\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0240 - accuracy: 0.5432\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0239 - accuracy: 0.5401\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0224 - accuracy: 0.5410\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0216 - accuracy: 0.5481\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0202 - accuracy: 0.5440\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0197 - accuracy: 0.5469\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0201 - accuracy: 0.5459\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0182 - accuracy: 0.5472\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0198 - accuracy: 0.5443\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 1.0174 - accuracy: 0.5473\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0175 - accuracy: 0.5455\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0185 - accuracy: 0.5454\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0154 - accuracy: 0.5462\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0149 - accuracy: 0.5451\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0126 - accuracy: 0.5479\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0145 - accuracy: 0.5499\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 21us/step - loss: 1.0129 - accuracy: 0.5472\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0128 - accuracy: 0.5448\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0116 - accuracy: 0.5470\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0110 - accuracy: 0.5483\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0118 - accuracy: 0.5473\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0105 - accuracy: 0.5466\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0094 - accuracy: 0.5474\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0090 - accuracy: 0.5465\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0103 - accuracy: 0.5499\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0079 - accuracy: 0.5463\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0078 - accuracy: 0.5487\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0074 - accuracy: 0.5510\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0084 - accuracy: 0.5494\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0060 - accuracy: 0.5506\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0060 - accuracy: 0.5509\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0057 - accuracy: 0.5501\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0064 - accuracy: 0.5496\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 1.0045 - accuracy: 0.5532\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0060 - accuracy: 0.5505\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0036 - accuracy: 0.5513\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0036 - accuracy: 0.5488\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0024 - accuracy: 0.5525\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0022 - accuracy: 0.5509\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0018 - accuracy: 0.5517\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0020 - accuracy: 0.5490\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0017 - accuracy: 0.5583\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0019 - accuracy: 0.5528\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0007 - accuracy: 0.5552\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9999 - accuracy: 0.5508\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0007 - accuracy: 0.5494\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0025 - accuracy: 0.5517\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9998 - accuracy: 0.5524\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9995 - accuracy: 0.5495\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9994 - accuracy: 0.5563\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9972 - accuracy: 0.5527\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9994 - accuracy: 0.5539\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9986 - accuracy: 0.5563\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9966 - accuracy: 0.5538\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9980 - accuracy: 0.5587\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9963 - accuracy: 0.5575\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9970 - accuracy: 0.5565\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9977 - accuracy: 0.5530\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9965 - accuracy: 0.5542\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9957 - accuracy: 0.5571\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9963 - accuracy: 0.5541\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9941 - accuracy: 0.5579\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9945 - accuracy: 0.5565\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 0.9922 - accuracy: 0.5546\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 0.9938 - accuracy: 0.5590\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9946 - accuracy: 0.5563\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9927 - accuracy: 0.5568\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9932 - accuracy: 0.5571\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9925 - accuracy: 0.5590\n",
            "807/807 [==============================] - 0s 38us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 34us/step - loss: 1.3534 - accuracy: 0.3655\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.2495 - accuracy: 0.4481\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.1706 - accuracy: 0.4717\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1335 - accuracy: 0.4932\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1114 - accuracy: 0.5061\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0987 - accuracy: 0.5105\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0894 - accuracy: 0.5158\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0837 - accuracy: 0.5196\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0804 - accuracy: 0.5187\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0757 - accuracy: 0.5242\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0704 - accuracy: 0.5239\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0663 - accuracy: 0.5265\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0655 - accuracy: 0.5253\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0620 - accuracy: 0.5232\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0597 - accuracy: 0.5304\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0565 - accuracy: 0.5298\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0556 - accuracy: 0.5273\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0509 - accuracy: 0.5344\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0520 - accuracy: 0.5304\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0459 - accuracy: 0.5342\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0448 - accuracy: 0.5368\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0432 - accuracy: 0.5362\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0429 - accuracy: 0.5384\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0386 - accuracy: 0.5395\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0376 - accuracy: 0.5390\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0358 - accuracy: 0.5382\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0346 - accuracy: 0.5366\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0352 - accuracy: 0.5363\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0335 - accuracy: 0.5396\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0317 - accuracy: 0.5392\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0297 - accuracy: 0.5436\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0295 - accuracy: 0.5423\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0265 - accuracy: 0.5444\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0270 - accuracy: 0.5417\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0269 - accuracy: 0.5419\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0244 - accuracy: 0.5436\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0245 - accuracy: 0.5418\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0231 - accuracy: 0.5468\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0222 - accuracy: 0.5454\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0211 - accuracy: 0.5433\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0208 - accuracy: 0.5461\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0218 - accuracy: 0.5415\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0182 - accuracy: 0.5485\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 1.0162 - accuracy: 0.5492\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0170 - accuracy: 0.5492\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0143 - accuracy: 0.5458\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0140 - accuracy: 0.5474\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0115 - accuracy: 0.5521\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0116 - accuracy: 0.5528\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0117 - accuracy: 0.5535\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0096 - accuracy: 0.5524\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0109 - accuracy: 0.5481\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0082 - accuracy: 0.5553\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0077 - accuracy: 0.5510\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0074 - accuracy: 0.5494\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0077 - accuracy: 0.5571\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0075 - accuracy: 0.5530\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0060 - accuracy: 0.5535\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0051 - accuracy: 0.5547\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0051 - accuracy: 0.5530\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0038 - accuracy: 0.5558\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0029 - accuracy: 0.5532\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0016 - accuracy: 0.5558\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 1.0021 - accuracy: 0.5576\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0003 - accuracy: 0.5561\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0002 - accuracy: 0.5583\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0015 - accuracy: 0.5572\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0001 - accuracy: 0.5553\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9992 - accuracy: 0.5589\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 0.9983 - accuracy: 0.5585\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9980 - accuracy: 0.5563\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9984 - accuracy: 0.5592\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9977 - accuracy: 0.5590\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9981 - accuracy: 0.5585\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9967 - accuracy: 0.5579\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9963 - accuracy: 0.5585\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9982 - accuracy: 0.5585\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9955 - accuracy: 0.5634\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9960 - accuracy: 0.5636\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9951 - accuracy: 0.5611\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9935 - accuracy: 0.5638\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9946 - accuracy: 0.5592\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9945 - accuracy: 0.5593\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9925 - accuracy: 0.5629\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9919 - accuracy: 0.5600\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9923 - accuracy: 0.5603\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9908 - accuracy: 0.5609\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9924 - accuracy: 0.5611\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9923 - accuracy: 0.5637\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9909 - accuracy: 0.5592\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9888 - accuracy: 0.5642\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9893 - accuracy: 0.5640\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9900 - accuracy: 0.5615\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9903 - accuracy: 0.5601\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9914 - accuracy: 0.5603\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9892 - accuracy: 0.5592\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9905 - accuracy: 0.5608\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9872 - accuracy: 0.5608\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9887 - accuracy: 0.5609\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9892 - accuracy: 0.5578\n",
            "807/807 [==============================] - 0s 39us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 31us/step - loss: 1.3150 - accuracy: 0.3893\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.1822 - accuracy: 0.4793\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.1396 - accuracy: 0.4986\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1194 - accuracy: 0.5009\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.1062 - accuracy: 0.5087\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0971 - accuracy: 0.5085\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0877 - accuracy: 0.5205\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0818 - accuracy: 0.5210\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0764 - accuracy: 0.5206\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0706 - accuracy: 0.5261\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0672 - accuracy: 0.5205\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0631 - accuracy: 0.5236\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0591 - accuracy: 0.5275\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0564 - accuracy: 0.5311\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0514 - accuracy: 0.5326\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0496 - accuracy: 0.5324\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0476 - accuracy: 0.5309\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0465 - accuracy: 0.5294\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0429 - accuracy: 0.5326\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0409 - accuracy: 0.5368\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0389 - accuracy: 0.5363\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0386 - accuracy: 0.5373\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0362 - accuracy: 0.5385\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0352 - accuracy: 0.5367\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0345 - accuracy: 0.5371\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0330 - accuracy: 0.5397\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0331 - accuracy: 0.5390\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0325 - accuracy: 0.5407\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0311 - accuracy: 0.5396\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0305 - accuracy: 0.5392\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0292 - accuracy: 0.5395\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0279 - accuracy: 0.5407\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0284 - accuracy: 0.5432\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0273 - accuracy: 0.5459\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0270 - accuracy: 0.5401\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0253 - accuracy: 0.5418\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0250 - accuracy: 0.5447\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0242 - accuracy: 0.5444\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0239 - accuracy: 0.5448\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0240 - accuracy: 0.5466\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0225 - accuracy: 0.5437\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0221 - accuracy: 0.5448\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0200 - accuracy: 0.5463\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0205 - accuracy: 0.5466\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0203 - accuracy: 0.5484\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0187 - accuracy: 0.5483\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0188 - accuracy: 0.5462\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0173 - accuracy: 0.5452\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0179 - accuracy: 0.5465\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0165 - accuracy: 0.5468\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0151 - accuracy: 0.5466\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0165 - accuracy: 0.5457\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0161 - accuracy: 0.5476\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0156 - accuracy: 0.5470\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0141 - accuracy: 0.5502\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0136 - accuracy: 0.5465\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0128 - accuracy: 0.5473\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0122 - accuracy: 0.5495\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0113 - accuracy: 0.5519\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0126 - accuracy: 0.5503\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0105 - accuracy: 0.5481\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0114 - accuracy: 0.5491\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0116 - accuracy: 0.5501\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0116 - accuracy: 0.5476\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0097 - accuracy: 0.5492\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0087 - accuracy: 0.5513\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0078 - accuracy: 0.5502\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0072 - accuracy: 0.5519\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0068 - accuracy: 0.5505\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0066 - accuracy: 0.5502\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0064 - accuracy: 0.5496\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0068 - accuracy: 0.5568\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0054 - accuracy: 0.5543\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0062 - accuracy: 0.5516\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0055 - accuracy: 0.5523\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0056 - accuracy: 0.5523\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0034 - accuracy: 0.5527\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0036 - accuracy: 0.5530\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0026 - accuracy: 0.5545\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0017 - accuracy: 0.5546\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0019 - accuracy: 0.5509\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0014 - accuracy: 0.5564\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0020 - accuracy: 0.5524\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9999 - accuracy: 0.5563\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0002 - accuracy: 0.5550\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0003 - accuracy: 0.5524\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0007 - accuracy: 0.5528\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9987 - accuracy: 0.5541\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9994 - accuracy: 0.5568\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9987 - accuracy: 0.5523\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9982 - accuracy: 0.5558\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9983 - accuracy: 0.5572\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9971 - accuracy: 0.5594\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9961 - accuracy: 0.5575\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9972 - accuracy: 0.5541\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9955 - accuracy: 0.5563\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9968 - accuracy: 0.5535\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9950 - accuracy: 0.5546\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9948 - accuracy: 0.5586\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9941 - accuracy: 0.5585\n",
            "807/807 [==============================] - 0s 41us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 32us/step - loss: 1.3525 - accuracy: 0.3422\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.2331 - accuracy: 0.4480\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1614 - accuracy: 0.4767\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.1282 - accuracy: 0.4911\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.1103 - accuracy: 0.5075\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1000 - accuracy: 0.5086\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0922 - accuracy: 0.5122\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0850 - accuracy: 0.5166\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0799 - accuracy: 0.5211\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0761 - accuracy: 0.5192\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0685 - accuracy: 0.5272\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0648 - accuracy: 0.5268\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0604 - accuracy: 0.5216\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0576 - accuracy: 0.5300\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0565 - accuracy: 0.5326\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0510 - accuracy: 0.5328\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0492 - accuracy: 0.5338\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0455 - accuracy: 0.5355\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0451 - accuracy: 0.5348\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0433 - accuracy: 0.5364\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0417 - accuracy: 0.5368\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0409 - accuracy: 0.5368\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0380 - accuracy: 0.5374\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0373 - accuracy: 0.5377\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0353 - accuracy: 0.5374\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0355 - accuracy: 0.5371\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0320 - accuracy: 0.5439\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0326 - accuracy: 0.5367\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0314 - accuracy: 0.5426\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0295 - accuracy: 0.5384\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0284 - accuracy: 0.5417\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0284 - accuracy: 0.5417\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0289 - accuracy: 0.5399\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0291 - accuracy: 0.5399\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0258 - accuracy: 0.5435\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0252 - accuracy: 0.5377\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0235 - accuracy: 0.5451\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0237 - accuracy: 0.5411\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0231 - accuracy: 0.5457\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0222 - accuracy: 0.5418\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0214 - accuracy: 0.5443\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0211 - accuracy: 0.5450\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0224 - accuracy: 0.5410\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0212 - accuracy: 0.5480\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0189 - accuracy: 0.5452\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0199 - accuracy: 0.5448\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0200 - accuracy: 0.5485\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0184 - accuracy: 0.5459\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0167 - accuracy: 0.5477\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0178 - accuracy: 0.5466\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0171 - accuracy: 0.5440\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0166 - accuracy: 0.5476\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0161 - accuracy: 0.5452\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0150 - accuracy: 0.5476\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0156 - accuracy: 0.5487\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0138 - accuracy: 0.5483\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0140 - accuracy: 0.5536\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0136 - accuracy: 0.5501\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0139 - accuracy: 0.5491\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0147 - accuracy: 0.5487\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0122 - accuracy: 0.5472\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0125 - accuracy: 0.5499\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0123 - accuracy: 0.5485\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0118 - accuracy: 0.5535\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0113 - accuracy: 0.5503\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0092 - accuracy: 0.5542\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0099 - accuracy: 0.5509\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0097 - accuracy: 0.5517\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0088 - accuracy: 0.5543\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0103 - accuracy: 0.5473\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0073 - accuracy: 0.5524\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0086 - accuracy: 0.5512\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0086 - accuracy: 0.5512\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0079 - accuracy: 0.5517\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0065 - accuracy: 0.5499\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0062 - accuracy: 0.5545\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0056 - accuracy: 0.5538\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0062 - accuracy: 0.5561\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0054 - accuracy: 0.5495\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0060 - accuracy: 0.5514\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0048 - accuracy: 0.5536\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0049 - accuracy: 0.5542\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0028 - accuracy: 0.5549\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0045 - accuracy: 0.5557\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0022 - accuracy: 0.5593\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0039 - accuracy: 0.5530\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0040 - accuracy: 0.5583\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0017 - accuracy: 0.5547\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0010 - accuracy: 0.5565\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9996 - accuracy: 0.5543\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0016 - accuracy: 0.5525\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0012 - accuracy: 0.5574\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9996 - accuracy: 0.5603\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0001 - accuracy: 0.5590\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0010 - accuracy: 0.5552\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9994 - accuracy: 0.5547\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0000 - accuracy: 0.5553\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0001 - accuracy: 0.5578\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9987 - accuracy: 0.5558\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9998 - accuracy: 0.5619\n",
            "807/807 [==============================] - 0s 36us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 32us/step - loss: 1.3558 - accuracy: 0.3458\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.2617 - accuracy: 0.4487\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.1632 - accuracy: 0.4899\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.1227 - accuracy: 0.5008\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1074 - accuracy: 0.5122\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0977 - accuracy: 0.5118\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0915 - accuracy: 0.5114\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0879 - accuracy: 0.5166\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0832 - accuracy: 0.5109\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0792 - accuracy: 0.5171\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0741 - accuracy: 0.5221\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0706 - accuracy: 0.5227\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0683 - accuracy: 0.5228\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0645 - accuracy: 0.5236\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0617 - accuracy: 0.5254\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0587 - accuracy: 0.5271\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0572 - accuracy: 0.5247\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0532 - accuracy: 0.5293\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0518 - accuracy: 0.5295\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0490 - accuracy: 0.5286\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0488 - accuracy: 0.5323\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0451 - accuracy: 0.5368\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0430 - accuracy: 0.5328\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0427 - accuracy: 0.5341\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0404 - accuracy: 0.5364\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0401 - accuracy: 0.5349\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0387 - accuracy: 0.5352\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0359 - accuracy: 0.5444\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0347 - accuracy: 0.5403\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0343 - accuracy: 0.5404\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0324 - accuracy: 0.5368\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0315 - accuracy: 0.5429\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0306 - accuracy: 0.5428\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0270 - accuracy: 0.5433\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0271 - accuracy: 0.5465\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0259 - accuracy: 0.5472\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0242 - accuracy: 0.5462\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0238 - accuracy: 0.5455\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0228 - accuracy: 0.5494\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0243 - accuracy: 0.5455\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0211 - accuracy: 0.5495\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0204 - accuracy: 0.5505\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0196 - accuracy: 0.5506\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0183 - accuracy: 0.5477\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0171 - accuracy: 0.5495\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0171 - accuracy: 0.5496\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0163 - accuracy: 0.5469\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0167 - accuracy: 0.5502\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0158 - accuracy: 0.5502\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0136 - accuracy: 0.5534\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0145 - accuracy: 0.5512\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0136 - accuracy: 0.5549\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0128 - accuracy: 0.5539\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0117 - accuracy: 0.5501\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0106 - accuracy: 0.5517\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0106 - accuracy: 0.5520\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0118 - accuracy: 0.5539\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0089 - accuracy: 0.5542\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0091 - accuracy: 0.5513\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0078 - accuracy: 0.5502\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0087 - accuracy: 0.5530\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0072 - accuracy: 0.5508\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0082 - accuracy: 0.5527\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0077 - accuracy: 0.5512\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0067 - accuracy: 0.5516\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0082 - accuracy: 0.5468\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0039 - accuracy: 0.5568\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0053 - accuracy: 0.5556\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0048 - accuracy: 0.5553\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0036 - accuracy: 0.5560\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0038 - accuracy: 0.5557\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0030 - accuracy: 0.5524\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0021 - accuracy: 0.5547\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0029 - accuracy: 0.5535\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0022 - accuracy: 0.5523\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0030 - accuracy: 0.5524\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0002 - accuracy: 0.5554\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0022 - accuracy: 0.5542\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0011 - accuracy: 0.5593\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9997 - accuracy: 0.5546\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9984 - accuracy: 0.5553\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9993 - accuracy: 0.5563\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9995 - accuracy: 0.5557\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0022 - accuracy: 0.5513\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9969 - accuracy: 0.5556\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9976 - accuracy: 0.5589\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9980 - accuracy: 0.5574\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9959 - accuracy: 0.5611\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9975 - accuracy: 0.5503\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9962 - accuracy: 0.5622\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9953 - accuracy: 0.5582\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9954 - accuracy: 0.5578\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9947 - accuracy: 0.5561\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9941 - accuracy: 0.5572\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9946 - accuracy: 0.5605\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9947 - accuracy: 0.5587\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9930 - accuracy: 0.5568\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9953 - accuracy: 0.5587\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9947 - accuracy: 0.5553\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9945 - accuracy: 0.5550\n",
            "807/807 [==============================] - 0s 35us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 31us/step - loss: 1.3489 - accuracy: 0.3356\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.2463 - accuracy: 0.4337\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1969 - accuracy: 0.4717\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.1498 - accuracy: 0.4973\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1217 - accuracy: 0.5035\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1046 - accuracy: 0.5116\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0938 - accuracy: 0.5155\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0891 - accuracy: 0.5193\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0838 - accuracy: 0.5211\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0751 - accuracy: 0.5205\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0704 - accuracy: 0.5255\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0656 - accuracy: 0.5272\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0626 - accuracy: 0.5291\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0579 - accuracy: 0.5315\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0541 - accuracy: 0.5326\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0514 - accuracy: 0.5316\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0511 - accuracy: 0.5371\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0476 - accuracy: 0.5364\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0439 - accuracy: 0.5352\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0421 - accuracy: 0.5360\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0416 - accuracy: 0.5393\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0407 - accuracy: 0.5348\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0362 - accuracy: 0.5408\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0354 - accuracy: 0.5400\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0333 - accuracy: 0.5429\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0332 - accuracy: 0.5379\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0320 - accuracy: 0.5423\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0303 - accuracy: 0.5392\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0292 - accuracy: 0.5432\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0298 - accuracy: 0.5378\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0278 - accuracy: 0.5465\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0268 - accuracy: 0.5454\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0261 - accuracy: 0.5462\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0253 - accuracy: 0.5451\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0255 - accuracy: 0.5435\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0231 - accuracy: 0.5388\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0235 - accuracy: 0.5446\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0225 - accuracy: 0.5457\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0230 - accuracy: 0.5421\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0218 - accuracy: 0.5447\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0216 - accuracy: 0.5389\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0210 - accuracy: 0.5419\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0203 - accuracy: 0.5401\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0222 - accuracy: 0.5396\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0187 - accuracy: 0.5440\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0179 - accuracy: 0.5430\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0163 - accuracy: 0.5457\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0177 - accuracy: 0.5444\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0168 - accuracy: 0.5450\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0155 - accuracy: 0.5441\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0150 - accuracy: 0.5470\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0148 - accuracy: 0.5448\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0137 - accuracy: 0.5452\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0134 - accuracy: 0.5462\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0131 - accuracy: 0.5429\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0127 - accuracy: 0.5443\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0122 - accuracy: 0.5484\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0122 - accuracy: 0.5480\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0118 - accuracy: 0.5476\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0113 - accuracy: 0.5490\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0106 - accuracy: 0.5454\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0121 - accuracy: 0.5480\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0098 - accuracy: 0.5477\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0096 - accuracy: 0.5451\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0100 - accuracy: 0.5448\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0080 - accuracy: 0.5474\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0090 - accuracy: 0.5462\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0087 - accuracy: 0.5461\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0075 - accuracy: 0.5499\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0079 - accuracy: 0.5435\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0062 - accuracy: 0.5492\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0062 - accuracy: 0.5491\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0058 - accuracy: 0.5520\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0068 - accuracy: 0.5481\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0059 - accuracy: 0.5480\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0046 - accuracy: 0.5488\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0043 - accuracy: 0.5531\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0036 - accuracy: 0.5536\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0026 - accuracy: 0.5528\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0030 - accuracy: 0.5524\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0041 - accuracy: 0.5485\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0027 - accuracy: 0.5516\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0025 - accuracy: 0.5527\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0024 - accuracy: 0.5567\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0013 - accuracy: 0.5517\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0013 - accuracy: 0.5516\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0014 - accuracy: 0.5542\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0010 - accuracy: 0.5521\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9992 - accuracy: 0.5531\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9999 - accuracy: 0.5558\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9999 - accuracy: 0.5541\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9995 - accuracy: 0.5521\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9977 - accuracy: 0.5558\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9968 - accuracy: 0.5558\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9969 - accuracy: 0.5589\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9975 - accuracy: 0.5549\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9970 - accuracy: 0.5550\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9968 - accuracy: 0.5527\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9963 - accuracy: 0.5565\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9951 - accuracy: 0.5574\n",
            "807/807 [==============================] - 0s 40us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 32us/step - loss: 1.3384 - accuracy: 0.3548\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.1969 - accuracy: 0.4706\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1381 - accuracy: 0.4900\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1165 - accuracy: 0.5045\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1023 - accuracy: 0.5119\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0921 - accuracy: 0.5200\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0837 - accuracy: 0.5236\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0764 - accuracy: 0.5220\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0674 - accuracy: 0.5278\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0648 - accuracy: 0.5293\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0573 - accuracy: 0.5300\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0540 - accuracy: 0.5342\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0509 - accuracy: 0.5334\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0478 - accuracy: 0.5352\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0445 - accuracy: 0.5349\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0421 - accuracy: 0.5370\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0401 - accuracy: 0.5360\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0384 - accuracy: 0.5342\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0375 - accuracy: 0.5373\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0357 - accuracy: 0.5381\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0333 - accuracy: 0.5382\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0327 - accuracy: 0.5388\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0313 - accuracy: 0.5360\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0307 - accuracy: 0.5450\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0305 - accuracy: 0.5392\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0289 - accuracy: 0.5411\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0274 - accuracy: 0.5403\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0284 - accuracy: 0.5423\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0257 - accuracy: 0.5455\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 1.0257 - accuracy: 0.5462\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0241 - accuracy: 0.5422\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0257 - accuracy: 0.5469\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0218 - accuracy: 0.5451\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0216 - accuracy: 0.5466\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0215 - accuracy: 0.5480\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 1.0219 - accuracy: 0.5487\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0192 - accuracy: 0.5492\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0188 - accuracy: 0.5528\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0191 - accuracy: 0.5488\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0170 - accuracy: 0.5519\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0167 - accuracy: 0.5502\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0162 - accuracy: 0.5496\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0170 - accuracy: 0.5512\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0162 - accuracy: 0.5503\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0165 - accuracy: 0.5498\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0153 - accuracy: 0.5513\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0143 - accuracy: 0.5512\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0125 - accuracy: 0.5554\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0129 - accuracy: 0.5550\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0131 - accuracy: 0.5530\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0118 - accuracy: 0.5508\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0113 - accuracy: 0.5525\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0120 - accuracy: 0.5503\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0123 - accuracy: 0.5550\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0118 - accuracy: 0.5495\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0104 - accuracy: 0.5491\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0101 - accuracy: 0.5519\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0110 - accuracy: 0.5502\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0086 - accuracy: 0.5547\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0081 - accuracy: 0.5528\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0077 - accuracy: 0.5546\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0087 - accuracy: 0.5531\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0067 - accuracy: 0.5539\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0050 - accuracy: 0.5550\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0059 - accuracy: 0.5578\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0046 - accuracy: 0.5528\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0061 - accuracy: 0.5531\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0038 - accuracy: 0.5536\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0034 - accuracy: 0.5557\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0041 - accuracy: 0.5517\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0040 - accuracy: 0.5564\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0029 - accuracy: 0.5569\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0043 - accuracy: 0.5532\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 1.0021 - accuracy: 0.5553\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0021 - accuracy: 0.5571\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0010 - accuracy: 0.5569\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0008 - accuracy: 0.5585\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0010 - accuracy: 0.5569\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0000 - accuracy: 0.5558\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9999 - accuracy: 0.5576\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9994 - accuracy: 0.5558\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9981 - accuracy: 0.5583\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9990 - accuracy: 0.5601\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9986 - accuracy: 0.5558\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9983 - accuracy: 0.5587\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9963 - accuracy: 0.5609\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9981 - accuracy: 0.5561\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9964 - accuracy: 0.5563\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0000 - accuracy: 0.5593\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 0.9963 - accuracy: 0.5605\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9971 - accuracy: 0.5568\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9964 - accuracy: 0.5552\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9977 - accuracy: 0.5572\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9948 - accuracy: 0.5572\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9940 - accuracy: 0.5567\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9956 - accuracy: 0.5605\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9947 - accuracy: 0.5601\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9939 - accuracy: 0.5596\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9941 - accuracy: 0.5575\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9933 - accuracy: 0.5604\n",
            "807/807 [==============================] - 0s 38us/step\n",
            "Epoch 1/100\n",
            "7261/7261 [==============================] - 0s 34us/step - loss: 1.3266 - accuracy: 0.3969\n",
            "Epoch 2/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1785 - accuracy: 0.4684\n",
            "Epoch 3/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.1317 - accuracy: 0.4899\n",
            "Epoch 4/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1148 - accuracy: 0.5002\n",
            "Epoch 5/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.1056 - accuracy: 0.5082\n",
            "Epoch 6/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0991 - accuracy: 0.5115\n",
            "Epoch 7/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0929 - accuracy: 0.5170\n",
            "Epoch 8/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0873 - accuracy: 0.5163\n",
            "Epoch 9/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0837 - accuracy: 0.5187\n",
            "Epoch 10/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0782 - accuracy: 0.5218\n",
            "Epoch 11/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0741 - accuracy: 0.5181\n",
            "Epoch 12/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0690 - accuracy: 0.5207\n",
            "Epoch 13/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0646 - accuracy: 0.5271\n",
            "Epoch 14/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0608 - accuracy: 0.5306\n",
            "Epoch 15/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0565 - accuracy: 0.5304\n",
            "Epoch 16/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0554 - accuracy: 0.5291\n",
            "Epoch 17/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0531 - accuracy: 0.5302\n",
            "Epoch 18/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0473 - accuracy: 0.5363\n",
            "Epoch 19/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0443 - accuracy: 0.5353\n",
            "Epoch 20/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0440 - accuracy: 0.5366\n",
            "Epoch 21/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0409 - accuracy: 0.5319\n",
            "Epoch 22/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0384 - accuracy: 0.5385\n",
            "Epoch 23/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0382 - accuracy: 0.5351\n",
            "Epoch 24/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0344 - accuracy: 0.5381\n",
            "Epoch 25/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0337 - accuracy: 0.5382\n",
            "Epoch 26/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0325 - accuracy: 0.5406\n",
            "Epoch 27/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0306 - accuracy: 0.5404\n",
            "Epoch 28/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0292 - accuracy: 0.5384\n",
            "Epoch 29/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0312 - accuracy: 0.5384\n",
            "Epoch 30/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0275 - accuracy: 0.5444\n",
            "Epoch 31/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0287 - accuracy: 0.5444\n",
            "Epoch 32/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0261 - accuracy: 0.5461\n",
            "Epoch 33/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0252 - accuracy: 0.5423\n",
            "Epoch 34/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0249 - accuracy: 0.5483\n",
            "Epoch 35/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0227 - accuracy: 0.5495\n",
            "Epoch 36/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0210 - accuracy: 0.5465\n",
            "Epoch 37/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0220 - accuracy: 0.5458\n",
            "Epoch 38/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0198 - accuracy: 0.5512\n",
            "Epoch 39/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0192 - accuracy: 0.5470\n",
            "Epoch 40/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0190 - accuracy: 0.5502\n",
            "Epoch 41/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0185 - accuracy: 0.5462\n",
            "Epoch 42/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0190 - accuracy: 0.5468\n",
            "Epoch 43/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0170 - accuracy: 0.5499\n",
            "Epoch 44/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0169 - accuracy: 0.5516\n",
            "Epoch 45/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0174 - accuracy: 0.5516\n",
            "Epoch 46/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0145 - accuracy: 0.5536\n",
            "Epoch 47/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0157 - accuracy: 0.5502\n",
            "Epoch 48/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0145 - accuracy: 0.5534\n",
            "Epoch 49/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0140 - accuracy: 0.5531\n",
            "Epoch 50/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0144 - accuracy: 0.5496\n",
            "Epoch 51/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0116 - accuracy: 0.5549\n",
            "Epoch 52/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0128 - accuracy: 0.5494\n",
            "Epoch 53/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0104 - accuracy: 0.5545\n",
            "Epoch 54/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0103 - accuracy: 0.5549\n",
            "Epoch 55/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0105 - accuracy: 0.5549\n",
            "Epoch 56/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0098 - accuracy: 0.5532\n",
            "Epoch 57/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0103 - accuracy: 0.5517\n",
            "Epoch 58/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0100 - accuracy: 0.5536\n",
            "Epoch 59/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0094 - accuracy: 0.5521\n",
            "Epoch 60/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0081 - accuracy: 0.5542\n",
            "Epoch 61/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0082 - accuracy: 0.5550\n",
            "Epoch 62/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0086 - accuracy: 0.5528\n",
            "Epoch 63/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0074 - accuracy: 0.5534\n",
            "Epoch 64/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0064 - accuracy: 0.5539\n",
            "Epoch 65/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0055 - accuracy: 0.5576\n",
            "Epoch 66/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 1.0064 - accuracy: 0.5549\n",
            "Epoch 67/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0060 - accuracy: 0.5567\n",
            "Epoch 68/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0064 - accuracy: 0.5550\n",
            "Epoch 69/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0043 - accuracy: 0.5564\n",
            "Epoch 70/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0036 - accuracy: 0.5571\n",
            "Epoch 71/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0028 - accuracy: 0.5543\n",
            "Epoch 72/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0049 - accuracy: 0.5564\n",
            "Epoch 73/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0031 - accuracy: 0.5542\n",
            "Epoch 74/100\n",
            "7261/7261 [==============================] - 0s 14us/step - loss: 1.0022 - accuracy: 0.5565\n",
            "Epoch 75/100\n",
            "7261/7261 [==============================] - 0s 12us/step - loss: 1.0019 - accuracy: 0.5576\n",
            "Epoch 76/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 1.0005 - accuracy: 0.5542\n",
            "Epoch 77/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0012 - accuracy: 0.5561\n",
            "Epoch 78/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 1.0014 - accuracy: 0.5560\n",
            "Epoch 79/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 1.0001 - accuracy: 0.5568\n",
            "Epoch 80/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0007 - accuracy: 0.5563\n",
            "Epoch 81/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 1.0013 - accuracy: 0.5545\n",
            "Epoch 82/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9991 - accuracy: 0.5560\n",
            "Epoch 83/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9991 - accuracy: 0.5552\n",
            "Epoch 84/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9988 - accuracy: 0.5553\n",
            "Epoch 85/100\n",
            "7261/7261 [==============================] - 0s 13us/step - loss: 0.9992 - accuracy: 0.5563\n",
            "Epoch 86/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9986 - accuracy: 0.5594\n",
            "Epoch 87/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9973 - accuracy: 0.5561\n",
            "Epoch 88/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9983 - accuracy: 0.5571\n",
            "Epoch 89/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9978 - accuracy: 0.5589\n",
            "Epoch 90/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9965 - accuracy: 0.5549\n",
            "Epoch 91/100\n",
            "7261/7261 [==============================] - 0s 20us/step - loss: 0.9974 - accuracy: 0.5580\n",
            "Epoch 92/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9960 - accuracy: 0.5567\n",
            "Epoch 93/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9961 - accuracy: 0.5585\n",
            "Epoch 94/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9954 - accuracy: 0.5553\n",
            "Epoch 95/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9955 - accuracy: 0.5578\n",
            "Epoch 96/100\n",
            "7261/7261 [==============================] - 0s 19us/step - loss: 0.9961 - accuracy: 0.5541\n",
            "Epoch 97/100\n",
            "7261/7261 [==============================] - 0s 15us/step - loss: 0.9962 - accuracy: 0.5556\n",
            "Epoch 98/100\n",
            "7261/7261 [==============================] - 0s 17us/step - loss: 0.9937 - accuracy: 0.5637\n",
            "Epoch 99/100\n",
            "7261/7261 [==============================] - 0s 16us/step - loss: 0.9949 - accuracy: 0.5554\n",
            "Epoch 100/100\n",
            "7261/7261 [==============================] - 0s 18us/step - loss: 0.9945 - accuracy: 0.5563\n",
            "807/807 [==============================] - 0s 38us/step\n",
            "Epoch 1/100\n",
            "7262/7262 [==============================] - 0s 31us/step - loss: 1.3519 - accuracy: 0.3514\n",
            "Epoch 2/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.2129 - accuracy: 0.4482\n",
            "Epoch 3/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.1444 - accuracy: 0.4935\n",
            "Epoch 4/100\n",
            "7262/7262 [==============================] - 0s 13us/step - loss: 1.1100 - accuracy: 0.5034\n",
            "Epoch 5/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0962 - accuracy: 0.5102\n",
            "Epoch 6/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0881 - accuracy: 0.5176\n",
            "Epoch 7/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0777 - accuracy: 0.5245\n",
            "Epoch 8/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0705 - accuracy: 0.5328\n",
            "Epoch 9/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0654 - accuracy: 0.5310\n",
            "Epoch 10/100\n",
            "7262/7262 [==============================] - 0s 13us/step - loss: 1.0605 - accuracy: 0.5321\n",
            "Epoch 11/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0567 - accuracy: 0.5335\n",
            "Epoch 12/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0536 - accuracy: 0.5328\n",
            "Epoch 13/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0514 - accuracy: 0.5348\n",
            "Epoch 14/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0486 - accuracy: 0.5361\n",
            "Epoch 15/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0468 - accuracy: 0.5372\n",
            "Epoch 16/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0424 - accuracy: 0.5373\n",
            "Epoch 17/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0415 - accuracy: 0.5342\n",
            "Epoch 18/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0389 - accuracy: 0.5355\n",
            "Epoch 19/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0383 - accuracy: 0.5394\n",
            "Epoch 20/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0351 - accuracy: 0.5381\n",
            "Epoch 21/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0338 - accuracy: 0.5409\n",
            "Epoch 22/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0312 - accuracy: 0.5421\n",
            "Epoch 23/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0308 - accuracy: 0.5395\n",
            "Epoch 24/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0284 - accuracy: 0.5437\n",
            "Epoch 25/100\n",
            "7262/7262 [==============================] - 0s 20us/step - loss: 1.0269 - accuracy: 0.5439\n",
            "Epoch 26/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0265 - accuracy: 0.5417\n",
            "Epoch 27/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0258 - accuracy: 0.5431\n",
            "Epoch 28/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0246 - accuracy: 0.5435\n",
            "Epoch 29/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0227 - accuracy: 0.5454\n",
            "Epoch 30/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0211 - accuracy: 0.5456\n",
            "Epoch 31/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0228 - accuracy: 0.5428\n",
            "Epoch 32/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0196 - accuracy: 0.5453\n",
            "Epoch 33/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0198 - accuracy: 0.5446\n",
            "Epoch 34/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0183 - accuracy: 0.5453\n",
            "Epoch 35/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0184 - accuracy: 0.5467\n",
            "Epoch 36/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0171 - accuracy: 0.5476\n",
            "Epoch 37/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0156 - accuracy: 0.5494\n",
            "Epoch 38/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0149 - accuracy: 0.5454\n",
            "Epoch 39/100\n",
            "7262/7262 [==============================] - 0s 12us/step - loss: 1.0143 - accuracy: 0.5475\n",
            "Epoch 40/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0130 - accuracy: 0.5468\n",
            "Epoch 41/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0119 - accuracy: 0.5523\n",
            "Epoch 42/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0121 - accuracy: 0.5483\n",
            "Epoch 43/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0110 - accuracy: 0.5504\n",
            "Epoch 44/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0112 - accuracy: 0.5500\n",
            "Epoch 45/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0097 - accuracy: 0.5510\n",
            "Epoch 46/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0096 - accuracy: 0.5472\n",
            "Epoch 47/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0084 - accuracy: 0.5472\n",
            "Epoch 48/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0083 - accuracy: 0.5521\n",
            "Epoch 49/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0075 - accuracy: 0.5536\n",
            "Epoch 50/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0071 - accuracy: 0.5526\n",
            "Epoch 51/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0089 - accuracy: 0.5545\n",
            "Epoch 52/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0073 - accuracy: 0.5526\n",
            "Epoch 53/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0056 - accuracy: 0.5533\n",
            "Epoch 54/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0045 - accuracy: 0.5545\n",
            "Epoch 55/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0048 - accuracy: 0.5538\n",
            "Epoch 56/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0032 - accuracy: 0.5540\n",
            "Epoch 57/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0035 - accuracy: 0.5548\n",
            "Epoch 58/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0044 - accuracy: 0.5551\n",
            "Epoch 59/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0043 - accuracy: 0.5530\n",
            "Epoch 60/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0051 - accuracy: 0.5518\n",
            "Epoch 61/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0054 - accuracy: 0.5538\n",
            "Epoch 62/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0005 - accuracy: 0.5581\n",
            "Epoch 63/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0004 - accuracy: 0.5560\n",
            "Epoch 64/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0004 - accuracy: 0.5588\n",
            "Epoch 65/100\n",
            "7262/7262 [==============================] - 0s 21us/step - loss: 1.0017 - accuracy: 0.5551\n",
            "Epoch 66/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0008 - accuracy: 0.5555\n",
            "Epoch 67/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0000 - accuracy: 0.5558\n",
            "Epoch 68/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9992 - accuracy: 0.5538\n",
            "Epoch 69/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9991 - accuracy: 0.5570\n",
            "Epoch 70/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9986 - accuracy: 0.5587\n",
            "Epoch 71/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9990 - accuracy: 0.5569\n",
            "Epoch 72/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0001 - accuracy: 0.5544\n",
            "Epoch 73/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9975 - accuracy: 0.5596\n",
            "Epoch 74/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9963 - accuracy: 0.5616\n",
            "Epoch 75/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9963 - accuracy: 0.5599\n",
            "Epoch 76/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9967 - accuracy: 0.5581\n",
            "Epoch 77/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9977 - accuracy: 0.5569\n",
            "Epoch 78/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9955 - accuracy: 0.5563\n",
            "Epoch 79/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9962 - accuracy: 0.5574\n",
            "Epoch 80/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9947 - accuracy: 0.5616\n",
            "Epoch 81/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 0.9952 - accuracy: 0.5631\n",
            "Epoch 82/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 0.9961 - accuracy: 0.5577\n",
            "Epoch 83/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9937 - accuracy: 0.5589\n",
            "Epoch 84/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9949 - accuracy: 0.5581\n",
            "Epoch 85/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 0.9937 - accuracy: 0.5632\n",
            "Epoch 86/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9928 - accuracy: 0.5599\n",
            "Epoch 87/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9928 - accuracy: 0.5587\n",
            "Epoch 88/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 0.9922 - accuracy: 0.5576\n",
            "Epoch 89/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9937 - accuracy: 0.5581\n",
            "Epoch 90/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9922 - accuracy: 0.5625\n",
            "Epoch 91/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9913 - accuracy: 0.5595\n",
            "Epoch 92/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9935 - accuracy: 0.5547\n",
            "Epoch 93/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9897 - accuracy: 0.5614\n",
            "Epoch 94/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9899 - accuracy: 0.5618\n",
            "Epoch 95/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9901 - accuracy: 0.5622\n",
            "Epoch 96/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9907 - accuracy: 0.5582\n",
            "Epoch 97/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9902 - accuracy: 0.5605\n",
            "Epoch 98/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9908 - accuracy: 0.5600\n",
            "Epoch 99/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9887 - accuracy: 0.5622\n",
            "Epoch 100/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9890 - accuracy: 0.5600\n",
            "806/806 [==============================] - 0s 41us/step\n",
            "Epoch 1/100\n",
            "7262/7262 [==============================] - 0s 31us/step - loss: 1.3359 - accuracy: 0.3573\n",
            "Epoch 2/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.2231 - accuracy: 0.4397\n",
            "Epoch 3/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.1539 - accuracy: 0.4730\n",
            "Epoch 4/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.1215 - accuracy: 0.4909\n",
            "Epoch 5/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.1056 - accuracy: 0.4985\n",
            "Epoch 6/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0937 - accuracy: 0.5090\n",
            "Epoch 7/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0858 - accuracy: 0.5096\n",
            "Epoch 8/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0795 - accuracy: 0.5143\n",
            "Epoch 9/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0743 - accuracy: 0.5202\n",
            "Epoch 10/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0692 - accuracy: 0.5164\n",
            "Epoch 11/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0642 - accuracy: 0.5205\n",
            "Epoch 12/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0612 - accuracy: 0.5193\n",
            "Epoch 13/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0581 - accuracy: 0.5241\n",
            "Epoch 14/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0526 - accuracy: 0.5245\n",
            "Epoch 15/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0507 - accuracy: 0.5267\n",
            "Epoch 16/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0467 - accuracy: 0.5282\n",
            "Epoch 17/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0458 - accuracy: 0.5285\n",
            "Epoch 18/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0442 - accuracy: 0.5281\n",
            "Epoch 19/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0421 - accuracy: 0.5285\n",
            "Epoch 20/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0372 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0344 - accuracy: 0.5308\n",
            "Epoch 22/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0323 - accuracy: 0.5336\n",
            "Epoch 23/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0319 - accuracy: 0.5317\n",
            "Epoch 24/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0318 - accuracy: 0.5329\n",
            "Epoch 25/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0290 - accuracy: 0.5403\n",
            "Epoch 26/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0286 - accuracy: 0.5388\n",
            "Epoch 27/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0277 - accuracy: 0.5421\n",
            "Epoch 28/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0263 - accuracy: 0.5380\n",
            "Epoch 29/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0275 - accuracy: 0.5394\n",
            "Epoch 30/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0251 - accuracy: 0.5397\n",
            "Epoch 31/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0241 - accuracy: 0.5434\n",
            "Epoch 32/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0224 - accuracy: 0.5419\n",
            "Epoch 33/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0238 - accuracy: 0.5420\n",
            "Epoch 34/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0231 - accuracy: 0.5402\n",
            "Epoch 35/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0207 - accuracy: 0.5426\n",
            "Epoch 36/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0216 - accuracy: 0.5432\n",
            "Epoch 37/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0199 - accuracy: 0.5421\n",
            "Epoch 38/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0199 - accuracy: 0.5445\n",
            "Epoch 39/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0196 - accuracy: 0.5372\n",
            "Epoch 40/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0188 - accuracy: 0.5431\n",
            "Epoch 41/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0191 - accuracy: 0.5449\n",
            "Epoch 42/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0240 - accuracy: 0.5413\n",
            "Epoch 43/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0181 - accuracy: 0.5476\n",
            "Epoch 44/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0209 - accuracy: 0.5395\n",
            "Epoch 45/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0162 - accuracy: 0.5445\n",
            "Epoch 46/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0149 - accuracy: 0.5449\n",
            "Epoch 47/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0148 - accuracy: 0.5439\n",
            "Epoch 48/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0156 - accuracy: 0.5482\n",
            "Epoch 49/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0164 - accuracy: 0.5430\n",
            "Epoch 50/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0146 - accuracy: 0.5483\n",
            "Epoch 51/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0148 - accuracy: 0.5511\n",
            "Epoch 52/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0138 - accuracy: 0.5468\n",
            "Epoch 53/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0117 - accuracy: 0.5496\n",
            "Epoch 54/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0122 - accuracy: 0.5508\n",
            "Epoch 55/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0126 - accuracy: 0.5441\n",
            "Epoch 56/100\n",
            "7262/7262 [==============================] - 0s 19us/step - loss: 1.0108 - accuracy: 0.5490\n",
            "Epoch 57/100\n",
            "7262/7262 [==============================] - 0s 20us/step - loss: 1.0122 - accuracy: 0.5490\n",
            "Epoch 58/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0100 - accuracy: 0.5494\n",
            "Epoch 59/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0118 - accuracy: 0.5478\n",
            "Epoch 60/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0109 - accuracy: 0.5508\n",
            "Epoch 61/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0088 - accuracy: 0.5472\n",
            "Epoch 62/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0110 - accuracy: 0.5497\n",
            "Epoch 63/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0106 - accuracy: 0.5479\n",
            "Epoch 64/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0091 - accuracy: 0.5475\n",
            "Epoch 65/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0088 - accuracy: 0.5504\n",
            "Epoch 66/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0088 - accuracy: 0.5463\n",
            "Epoch 67/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0116 - accuracy: 0.5474\n",
            "Epoch 68/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0073 - accuracy: 0.5516\n",
            "Epoch 69/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0064 - accuracy: 0.5496\n",
            "Epoch 70/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0071 - accuracy: 0.5486\n",
            "Epoch 71/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0086 - accuracy: 0.5497\n",
            "Epoch 72/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0063 - accuracy: 0.5545\n",
            "Epoch 73/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0062 - accuracy: 0.5503\n",
            "Epoch 74/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0055 - accuracy: 0.5478\n",
            "Epoch 75/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0042 - accuracy: 0.5537\n",
            "Epoch 76/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0050 - accuracy: 0.5482\n",
            "Epoch 77/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0053 - accuracy: 0.5490\n",
            "Epoch 78/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0042 - accuracy: 0.5515\n",
            "Epoch 79/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0032 - accuracy: 0.5519\n",
            "Epoch 80/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0035 - accuracy: 0.5492\n",
            "Epoch 81/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0033 - accuracy: 0.5522\n",
            "Epoch 82/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0044 - accuracy: 0.5500\n",
            "Epoch 83/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 1.0017 - accuracy: 0.5475\n",
            "Epoch 84/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0041 - accuracy: 0.5437\n",
            "Epoch 85/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0033 - accuracy: 0.5492\n",
            "Epoch 86/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0022 - accuracy: 0.5519\n",
            "Epoch 87/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0001 - accuracy: 0.5507\n",
            "Epoch 88/100\n",
            "7262/7262 [==============================] - 0s 14us/step - loss: 1.0012 - accuracy: 0.5508\n",
            "Epoch 89/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0012 - accuracy: 0.5504\n",
            "Epoch 90/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0027 - accuracy: 0.5548\n",
            "Epoch 91/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0001 - accuracy: 0.5481\n",
            "Epoch 92/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0003 - accuracy: 0.5516\n",
            "Epoch 93/100\n",
            "7262/7262 [==============================] - 0s 18us/step - loss: 1.0024 - accuracy: 0.5522\n",
            "Epoch 94/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 1.0010 - accuracy: 0.5478\n",
            "Epoch 95/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 0.9997 - accuracy: 0.5497\n",
            "Epoch 96/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9989 - accuracy: 0.5503\n",
            "Epoch 97/100\n",
            "7262/7262 [==============================] - 0s 15us/step - loss: 1.0008 - accuracy: 0.5492\n",
            "Epoch 98/100\n",
            "7262/7262 [==============================] - 0s 17us/step - loss: 0.9984 - accuracy: 0.5492\n",
            "Epoch 99/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9983 - accuracy: 0.5515\n",
            "Epoch 100/100\n",
            "7262/7262 [==============================] - 0s 16us/step - loss: 0.9988 - accuracy: 0.5556\n",
            "806/806 [==============================] - 0s 45us/step\n",
            "Baseline: 52.45% (1.54%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wBZrur0Zxugt",
        "colab": {}
      },
      "source": [
        "X_test = test_df.drop([\"ID\",\"Age\",\"Work_Experience\",\"Family_Size\",'Work_start_age', 'Family_Size_Excl_customer'],axis=1)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJlAdJRcx6Ok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4615097a-14f9-4483-9498-d7cc60654577"
      },
      "source": [
        "estimator.fit(X,y)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8068/8068 [==============================] - 0s 29us/step - loss: 1.3545 - accuracy: 0.3563\n",
            "Epoch 2/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.2088 - accuracy: 0.4549\n",
            "Epoch 3/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.1396 - accuracy: 0.4896\n",
            "Epoch 4/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.1105 - accuracy: 0.5048\n",
            "Epoch 5/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0961 - accuracy: 0.5128\n",
            "Epoch 6/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0871 - accuracy: 0.5143\n",
            "Epoch 7/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0819 - accuracy: 0.5176\n",
            "Epoch 8/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0762 - accuracy: 0.5218\n",
            "Epoch 9/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0711 - accuracy: 0.5270\n",
            "Epoch 10/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0683 - accuracy: 0.5259\n",
            "Epoch 11/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0646 - accuracy: 0.5319\n",
            "Epoch 12/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0633 - accuracy: 0.5306\n",
            "Epoch 13/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0584 - accuracy: 0.5288\n",
            "Epoch 14/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0556 - accuracy: 0.5322\n",
            "Epoch 15/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0552 - accuracy: 0.5332\n",
            "Epoch 16/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0509 - accuracy: 0.5379\n",
            "Epoch 17/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0494 - accuracy: 0.5357\n",
            "Epoch 18/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0476 - accuracy: 0.5379\n",
            "Epoch 19/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0467 - accuracy: 0.5383\n",
            "Epoch 20/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0438 - accuracy: 0.5408\n",
            "Epoch 21/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0419 - accuracy: 0.5379\n",
            "Epoch 22/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0411 - accuracy: 0.5388\n",
            "Epoch 23/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0384 - accuracy: 0.5405\n",
            "Epoch 24/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0380 - accuracy: 0.5395\n",
            "Epoch 25/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0368 - accuracy: 0.5412\n",
            "Epoch 26/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0357 - accuracy: 0.5441\n",
            "Epoch 27/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0343 - accuracy: 0.5412\n",
            "Epoch 28/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0340 - accuracy: 0.5392\n",
            "Epoch 29/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0329 - accuracy: 0.5383\n",
            "Epoch 30/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0315 - accuracy: 0.5400\n",
            "Epoch 31/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0304 - accuracy: 0.5435\n",
            "Epoch 32/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0279 - accuracy: 0.5446\n",
            "Epoch 33/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0280 - accuracy: 0.5434\n",
            "Epoch 34/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0266 - accuracy: 0.5487\n",
            "Epoch 35/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0267 - accuracy: 0.5438\n",
            "Epoch 36/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0254 - accuracy: 0.5469\n",
            "Epoch 37/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0254 - accuracy: 0.5439\n",
            "Epoch 38/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0239 - accuracy: 0.5457\n",
            "Epoch 39/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0234 - accuracy: 0.5444\n",
            "Epoch 40/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0223 - accuracy: 0.5446\n",
            "Epoch 41/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0209 - accuracy: 0.5486\n",
            "Epoch 42/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0216 - accuracy: 0.5466\n",
            "Epoch 43/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0211 - accuracy: 0.5466\n",
            "Epoch 44/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0194 - accuracy: 0.5467\n",
            "Epoch 45/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0202 - accuracy: 0.5451\n",
            "Epoch 46/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0194 - accuracy: 0.5412\n",
            "Epoch 47/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0182 - accuracy: 0.5467\n",
            "Epoch 48/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0178 - accuracy: 0.5488\n",
            "Epoch 49/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0175 - accuracy: 0.5500\n",
            "Epoch 50/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0173 - accuracy: 0.5488\n",
            "Epoch 51/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0170 - accuracy: 0.5483\n",
            "Epoch 52/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0152 - accuracy: 0.5481\n",
            "Epoch 53/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0150 - accuracy: 0.5454\n",
            "Epoch 54/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0151 - accuracy: 0.5476\n",
            "Epoch 55/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0146 - accuracy: 0.5477\n",
            "Epoch 56/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0141 - accuracy: 0.5477\n",
            "Epoch 57/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0142 - accuracy: 0.5444\n",
            "Epoch 58/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0131 - accuracy: 0.5514\n",
            "Epoch 59/100\n",
            "8068/8068 [==============================] - 0s 12us/step - loss: 1.0135 - accuracy: 0.5538\n",
            "Epoch 60/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0120 - accuracy: 0.5469\n",
            "Epoch 61/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0100 - accuracy: 0.5487\n",
            "Epoch 62/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0147 - accuracy: 0.5482\n",
            "Epoch 63/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0110 - accuracy: 0.5488\n",
            "Epoch 64/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0113 - accuracy: 0.5507\n",
            "Epoch 65/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0099 - accuracy: 0.5488\n",
            "Epoch 66/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0099 - accuracy: 0.5475\n",
            "Epoch 67/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0095 - accuracy: 0.5466\n",
            "Epoch 68/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0086 - accuracy: 0.5512\n",
            "Epoch 69/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0104 - accuracy: 0.5492\n",
            "Epoch 70/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0086 - accuracy: 0.5493\n",
            "Epoch 71/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0081 - accuracy: 0.5549\n",
            "Epoch 72/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0088 - accuracy: 0.5502\n",
            "Epoch 73/100\n",
            "8068/8068 [==============================] - 0s 20us/step - loss: 1.0090 - accuracy: 0.5497\n",
            "Epoch 74/100\n",
            "8068/8068 [==============================] - 0s 18us/step - loss: 1.0067 - accuracy: 0.5478\n",
            "Epoch 75/100\n",
            "8068/8068 [==============================] - 0s 14us/step - loss: 1.0059 - accuracy: 0.5526\n",
            "Epoch 76/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0074 - accuracy: 0.5507\n",
            "Epoch 77/100\n",
            "8068/8068 [==============================] - 0s 13us/step - loss: 1.0069 - accuracy: 0.5492\n",
            "Epoch 78/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0069 - accuracy: 0.5495\n",
            "Epoch 79/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0070 - accuracy: 0.5545\n",
            "Epoch 80/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0059 - accuracy: 0.5504\n",
            "Epoch 81/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0046 - accuracy: 0.5529\n",
            "Epoch 82/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0050 - accuracy: 0.5485\n",
            "Epoch 83/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0046 - accuracy: 0.5511\n",
            "Epoch 84/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0053 - accuracy: 0.5496\n",
            "Epoch 85/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0064 - accuracy: 0.5467\n",
            "Epoch 86/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0034 - accuracy: 0.5519\n",
            "Epoch 87/100\n",
            "8068/8068 [==============================] - 0s 18us/step - loss: 1.0051 - accuracy: 0.5506\n",
            "Epoch 88/100\n",
            "8068/8068 [==============================] - 0s 17us/step - loss: 1.0047 - accuracy: 0.5533\n",
            "Epoch 89/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0026 - accuracy: 0.5537\n",
            "Epoch 90/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0034 - accuracy: 0.5529\n",
            "Epoch 91/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0039 - accuracy: 0.5491\n",
            "Epoch 92/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0016 - accuracy: 0.5543\n",
            "Epoch 93/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0022 - accuracy: 0.5493\n",
            "Epoch 94/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0015 - accuracy: 0.5553\n",
            "Epoch 95/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0021 - accuracy: 0.5545\n",
            "Epoch 96/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0018 - accuracy: 0.5526\n",
            "Epoch 97/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0022 - accuracy: 0.5504\n",
            "Epoch 98/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0014 - accuracy: 0.5534\n",
            "Epoch 99/100\n",
            "8068/8068 [==============================] - 0s 16us/step - loss: 1.0019 - accuracy: 0.5532\n",
            "Epoch 100/100\n",
            "8068/8068 [==============================] - 0s 15us/step - loss: 1.0009 - accuracy: 0.5564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5bb6e5a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm0qsmyVyCx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f712922-b45a-459b-813a-9188a982a926"
      },
      "source": [
        "y_pred = estimator.predict(X_test)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2627/2627 [==============================] - 0s 10us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J6UjVOxxyPKH",
        "colab": {}
      },
      "source": [
        "submission_data = pd.concat([test_df['ID'],pd.Series(y_pred)],axis=1)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SPH0vKz7yPKY",
        "colab": {}
      },
      "source": [
        "Segmentation_Mapping_Inverse = {0:\"A\",1:\"B\",2:\"C\",3:\"D\"}"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6_q4E98ByPKg",
        "colab": {}
      },
      "source": [
        "submission_data[0] = submission_data[0].map(Segmentation_Mapping_Inverse)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0VHJ3-svyPKo",
        "colab": {}
      },
      "source": [
        "submission_data.columns = ['ID','Segmentation']"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fu0jMNSdyPKw",
        "colab": {}
      },
      "source": [
        "submission_data.to_csv(\"submission_keras_v3.csv\",index=False)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W0HURosvuVD",
        "colab_type": "text"
      },
      "source": [
        "## LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGK450nB1YU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "167e1e60-513d-48e5-e528-d0959adbe1c2"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Segmentation</th>\n",
              "      <th>Work_start_age</th>\n",
              "      <th>Family_Size_Excl_customer</th>\n",
              "      <th>age_category</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Ever_Married_No</th>\n",
              "      <th>Ever_Married_Yes</th>\n",
              "      <th>Profession_Artist</th>\n",
              "      <th>Profession_Doctor</th>\n",
              "      <th>Profession_Engineer</th>\n",
              "      <th>Profession_Entertainment</th>\n",
              "      <th>Profession_Executive</th>\n",
              "      <th>Profession_Healthcare</th>\n",
              "      <th>Profession_Homemaker</th>\n",
              "      <th>Profession_Lawyer</th>\n",
              "      <th>Profession_Marketing</th>\n",
              "      <th>Profession_Others</th>\n",
              "      <th>Var_1_Cat_1</th>\n",
              "      <th>Var_1_Cat_2</th>\n",
              "      <th>Var_1_Cat_3</th>\n",
              "      <th>Var_1_Cat_4</th>\n",
              "      <th>Var_1_Cat_5</th>\n",
              "      <th>Var_1_Cat_6</th>\n",
              "      <th>Var_1_Cat_7</th>\n",
              "      <th>Var_1_Cat_Unknown</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Work_Experience_Normalized</th>\n",
              "      <th>Family_Size_Normalized</th>\n",
              "      <th>Work_start_age_Normalized</th>\n",
              "      <th>Family_Size_Excl_customer_Normalized</th>\n",
              "      <th>Spend_Family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.281690</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.625</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8063</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8064</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.239437</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8065</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8066</th>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.126761</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8067</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.267606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8068 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Age  Graduated  ...  Family_Size_Excl_customer_Normalized  Spend_Family\n",
              "0      22          0  ...                                 0.375          0.00\n",
              "1      38          1  ...                                 0.250          0.25\n",
              "2      67          1  ...                                 0.000          0.00\n",
              "3      67          1  ...                                 0.125          0.25\n",
              "4      40          1  ...                                 0.625          1.25\n",
              "...   ...        ...  ...                                   ...           ...\n",
              "8063   22          0  ...                                 0.750          0.00\n",
              "8064   35          0  ...                                 0.375          0.00\n",
              "8065   33          1  ...                                 0.000          0.00\n",
              "8066   27          1  ...                                 0.375          0.00\n",
              "8067   37          1  ...                                 0.250          0.25\n",
              "\n",
              "[8068 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10STQd1Yz45H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = lgb.LGBMClassifier(n_estimators=100,learning_rate=0.1)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdDckFD50S2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f8215dd6-86cb-4940-bbe0-5a253add9fde"
      },
      "source": [
        "m1.fit(X_train,y_train)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zp3rrn5bu9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2844c351-497b-4f61-a8b0-d2fa7450a46a"
      },
      "source": [
        "print_score(m1)  "
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6743105051131082, 0.5210656753407683]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsLoVD8D0qQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5fafc6fb-9a77-4b6f-8b2f-959065b603c2"
      },
      "source": [
        "feat_importances = pd.Series(m1.feature_importances_, index=X_train.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bb71e8198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQOiyIe6joz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "124f49f7-f3b5-49ee-dd3c-5940022d2134"
      },
      "source": [
        "y_valid.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    474\n",
              "0    391\n",
              "2    380\n",
              "1    369\n",
              "Name: Segmentation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLtTJgMj1oO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "a915a9bb-b9d3-43c6-e2a9-e04eff8107e3"
      },
      "source": [
        "m1.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrIrbsKkD4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = test_df.drop([\"ID\",\"Age\",\"Work_Experience\",\"Family_Size\"],axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhivopg-kFky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = m1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v236TCUXkXT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data = pd.concat([test_df['ID'],pd.Series(y_pred)],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xew62O_Nkz96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Segmentation_Mapping_Inverse = {0:\"A\",1:\"B\",2:\"C\",3:\"D\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gfkYgNklVsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data[0] = submission_data[0].map(Segmentation_Mapping_Inverse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7V7tgUvlYCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data.columns = ['ID','Segmentation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG-NlwlIlful",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data.to_csv(\"submission_v1.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLjSVbA24HzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "0150aade-a704-4f3e-a28e-c8beea6b959f"
      },
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smWFsyJq4Qjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "610075d7-4f93-41b0-bf7c-e2976f8220d5"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Segmentation</th>\n",
              "      <th>Work_start_age</th>\n",
              "      <th>Family_Size_Excl_customer</th>\n",
              "      <th>age_category</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Ever_Married_No</th>\n",
              "      <th>Ever_Married_Yes</th>\n",
              "      <th>Profession_Artist</th>\n",
              "      <th>Profession_Doctor</th>\n",
              "      <th>Profession_Engineer</th>\n",
              "      <th>Profession_Entertainment</th>\n",
              "      <th>Profession_Executive</th>\n",
              "      <th>Profession_Healthcare</th>\n",
              "      <th>Profession_Homemaker</th>\n",
              "      <th>Profession_Lawyer</th>\n",
              "      <th>Profession_Marketing</th>\n",
              "      <th>Profession_Others</th>\n",
              "      <th>Var_1_Cat_1</th>\n",
              "      <th>Var_1_Cat_2</th>\n",
              "      <th>Var_1_Cat_3</th>\n",
              "      <th>Var_1_Cat_4</th>\n",
              "      <th>Var_1_Cat_5</th>\n",
              "      <th>Var_1_Cat_6</th>\n",
              "      <th>Var_1_Cat_7</th>\n",
              "      <th>Var_1_Cat_Unknown</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Work_Experience_Normalized</th>\n",
              "      <th>Family_Size_Normalized</th>\n",
              "      <th>Work_start_age_Normalized</th>\n",
              "      <th>Family_Size_Excl_customer_Normalized</th>\n",
              "      <th>Spend_Family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.281690</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.625</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8063</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8064</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.239437</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8065</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8066</th>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.126761</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8067</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.267606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8068 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Age  Graduated  ...  Family_Size_Excl_customer_Normalized  Spend_Family\n",
              "0      22          0  ...                                 0.375          0.00\n",
              "1      38          1  ...                                 0.250          0.25\n",
              "2      67          1  ...                                 0.000          0.00\n",
              "3      67          1  ...                                 0.125          0.25\n",
              "4      40          1  ...                                 0.625          1.25\n",
              "...   ...        ...  ...                                   ...           ...\n",
              "8063   22          0  ...                                 0.750          0.00\n",
              "8064   35          0  ...                                 0.375          0.00\n",
              "8065   33          1  ...                                 0.000          0.00\n",
              "8066   27          1  ...                                 0.375          0.00\n",
              "8067   37          1  ...                                 0.250          0.25\n",
              "\n",
              "[8068 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOeDAQgk4q1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "32880704-c814-4498-a2ef-77accb3247f8"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Work_start_age</th>\n",
              "      <th>Family_Size_Excl_customer</th>\n",
              "      <th>age_category</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Ever_Married_No</th>\n",
              "      <th>Ever_Married_Yes</th>\n",
              "      <th>Profession_Artist</th>\n",
              "      <th>Profession_Doctor</th>\n",
              "      <th>Profession_Engineer</th>\n",
              "      <th>Profession_Entertainment</th>\n",
              "      <th>Profession_Executive</th>\n",
              "      <th>Profession_Healthcare</th>\n",
              "      <th>Profession_Homemaker</th>\n",
              "      <th>Profession_Lawyer</th>\n",
              "      <th>Profession_Marketing</th>\n",
              "      <th>Profession_Others</th>\n",
              "      <th>Var_1_Cat_1</th>\n",
              "      <th>Var_1_Cat_2</th>\n",
              "      <th>Var_1_Cat_3</th>\n",
              "      <th>Var_1_Cat_4</th>\n",
              "      <th>Var_1_Cat_5</th>\n",
              "      <th>Var_1_Cat_6</th>\n",
              "      <th>Var_1_Cat_7</th>\n",
              "      <th>Var_1_Cat_Unknown</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Work_Experience_Normalized</th>\n",
              "      <th>Family_Size_Normalized</th>\n",
              "      <th>Work_start_age_Normalized</th>\n",
              "      <th>Family_Size_Excl_customer_Normalized</th>\n",
              "      <th>Spend_Family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>458989</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.253521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>458994</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.267606</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>458996</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>459000</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.577465</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>459001</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014085</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2622</th>\n",
              "      <td>467954</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.154930</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2623</th>\n",
              "      <td>467958</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.239437</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2624</th>\n",
              "      <td>467960</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>467961</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2626</th>\n",
              "      <td>467968</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.352113</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2627 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  Age  ...  Family_Size_Excl_customer_Normalized  Spend_Family\n",
              "0     458989   36  ...                                 0.000         0.000\n",
              "1     458994   37  ...                                 0.375         0.375\n",
              "2     458996   69  ...                                 0.000         0.000\n",
              "3     459000   59  ...                                 0.125         0.250\n",
              "4     459001   19  ...                                 0.375         0.000\n",
              "...      ...  ...  ...                                   ...           ...\n",
              "2622  467954   29  ...                                 0.375         0.000\n",
              "2623  467958   35  ...                                 0.000         0.000\n",
              "2624  467960   53  ...                                 0.125         0.000\n",
              "2625  467961   47  ...                                 0.500         1.000\n",
              "2626  467968   43  ...                                 0.250         0.000\n",
              "\n",
              "[2627 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFf4a0ko6RH0",
        "colab_type": "text"
      },
      "source": [
        "## Catboost kfold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHs30kK347O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "K = 5\n",
        "kf = KFold(n_splits = K, random_state = 7, shuffle = True)\n",
        "skf = StratifiedKFold(n_splits = K, random_state = 7, shuffle = True)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iAr3Clk48bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_ROUNDS = 1000\n",
        "OPTIMIZE_ROUNDS = False"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGcVgSzu5Ftr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHAc-2pi3zQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "2774731f-7ca8-45fc-cab2-c37e195cbe6e"
      },
      "source": [
        "X"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>age_category</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Ever_Married_No</th>\n",
              "      <th>Ever_Married_Yes</th>\n",
              "      <th>Profession_Artist</th>\n",
              "      <th>Profession_Doctor</th>\n",
              "      <th>Profession_Engineer</th>\n",
              "      <th>Profession_Entertainment</th>\n",
              "      <th>Profession_Executive</th>\n",
              "      <th>Profession_Healthcare</th>\n",
              "      <th>Profession_Homemaker</th>\n",
              "      <th>Profession_Lawyer</th>\n",
              "      <th>Profession_Marketing</th>\n",
              "      <th>Profession_Others</th>\n",
              "      <th>Var_1_Cat_1</th>\n",
              "      <th>Var_1_Cat_2</th>\n",
              "      <th>Var_1_Cat_3</th>\n",
              "      <th>Var_1_Cat_4</th>\n",
              "      <th>Var_1_Cat_5</th>\n",
              "      <th>Var_1_Cat_6</th>\n",
              "      <th>Var_1_Cat_7</th>\n",
              "      <th>Var_1_Cat_Unknown</th>\n",
              "      <th>Work_start_age_Normalized</th>\n",
              "      <th>Family_Size_Excl_customer_Normalized</th>\n",
              "      <th>Spend_Family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.625</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8063</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8064</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8065</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8066</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8067</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8068 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Graduated  ...  Spend_Family\n",
              "0             0  ...          0.00\n",
              "1             1  ...          0.25\n",
              "2             1  ...          0.00\n",
              "3             1  ...          0.25\n",
              "4             1  ...          1.25\n",
              "...         ...  ...           ...\n",
              "8063          0  ...          0.00\n",
              "8064          0  ...          0.00\n",
              "8065          1  ...          0.00\n",
              "8066          1  ...          0.00\n",
              "8067          1  ...          0.25\n",
              "\n",
              "[8068 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIfVYS8Hlr1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "cfc03a5f-aed9-4f35-c2cc-d2c01213e22a"
      },
      "source": [
        "X = train_df.drop(columns=['Segmentation','Age','Work_Experience','Family_Size',\n",
        "                            'Work_start_age','Family_Size_Excl_customer','Age_Normalized',\n",
        "                           'Work_Experience_Normalized','Family_Size_Normalized'],axis=1)\n",
        "y = train_df['Segmentation']\n",
        "X_test = test_df.drop(columns=['ID','Age','Work_Experience','Family_Size',\n",
        "                               'Work_start_age','Family_Size_Excl_customer','Age_Normalized',\n",
        "                           'Work_Experience_Normalized','Family_Size_Normalized'],axis=1)\n",
        "y_valid_pred = 0*y\n",
        "y_test_pred = 0\n",
        "accuracy = 0\n",
        "result={}\n",
        "cat_columns = []\n",
        "j=1\n",
        "model = CatBoostClassifier(n_estimators=MAX_ROUNDS,verbose=False)\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "    X_train, X_valid = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "    print(\"\\nFold - \", j)\n",
        "    \n",
        "    if OPTIMIZE_ROUNDS:\n",
        "        fit_model = model.fit( X_train, y_train, \n",
        "                               eval_set=[X_valid, y_valid],cat_features=cat_columns,\n",
        "                               use_best_model=True\n",
        "                             )\n",
        "        print( \"N trees = \", model.tree_count_ )\n",
        "    else:\n",
        "        fit_model = model.fit( X_train, y_train,cat_features=cat_columns )\n",
        "        \n",
        "    pred = fit_model.predict(X_valid)\n",
        "    y_valid_pred.iloc[test_index] = pred.reshape(-1)\n",
        "    print(accuracy_score(y_valid,pred))\n",
        "    accuracy+=accuracy_score(y_valid,pred)\n",
        "    y_test_pred += fit_model.predict(X_test)\n",
        "    result[j]=fit_model.predict(X_test)\n",
        "    j+=1\n",
        "results = y_test_pred / K  # Average test set predictions\n",
        "print(accuracy/5)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold -  1\n",
            "0.5074349442379182\n",
            "\n",
            "Fold -  2\n",
            "0.530359355638166\n",
            "\n",
            "Fold -  3\n",
            "0.5247831474597274\n",
            "\n",
            "Fold -  4\n",
            "0.5145691258524488\n",
            "\n",
            "Fold -  5\n",
            "0.5164290142591444\n",
            "0.518715117489481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj0wLhFz5H5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c2d8db69-67c6-4c2e-da9e-5fd90c738327"
      },
      "source": [
        "feat_importances = pd.Series(fit_model.feature_importances_, index=X_train.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bb7a620f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAD4CAYAAADGrB2DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcVZ3+8c9DWAIEAhpE9lYEkTUkHXaQKMOoIIugiFGJOCL+EBTEkRlccHSUkVFEQTEgBDUiIqCMOCyTGEEIJJ2QpMM+Q4ICKiAa9iDh+f1xT0Gl6D2drop53q9Xv+rec88953tvdVLfPudUlWwTERER0UpWa3YAEREREY2SoERERETLSYISERERLScJSkRERLScJCgRERHRclZvdgARfy9GjRrltra2ZocREbFSmT179mO2N2osT4ISMUja2tro6OhodhgRESsVSQ90VZ4pnoiIiGg5SVAiIiKi5SRBiYiIiJaTBCUiIiJaThbJRgySzocW03baNc0OY6Wy6MyDmh1CRLSojKBEREREy0mCEhERES0nCUqTSFoqaa6kBZIul7ROP8+/VNJ8SScPUjy3DEY7de1Nl9Ret98macFytPdUXTvvqyufKOnc5Ys2IiJaTRKU5nnW9mjbOwLPA8fXH5TU7fogSa8Fxtne2fbZgxGM7b0Go50h0Aa8r7dKy6Onex8REUMjCUpruAl4g6T9Jd0k6WrgTknDJV0sqVPS7ZLGl/rXA5uVEZh9JW0t6VpJs8v52wFIencZoZkn6cZStoOkmeXc+ZK2KeW1EQpJOquc1ynpqFK+fxkV+ZmkuyVNkaSBXKykYaWPWSWGj5byEZKmSppT+j60i9PPBPYt8ddGjzYt13+fpK/V9fO20tY8SVNL2W6SZpT7eYukN5byiZKuljQNmCppXUkXlXt1ezexIOk4SR2SOpY+s3ggtyMiIrqQvxSbrPy1/nbg2lI0BtjR9kJJnwJse6eSdFwvaVvgEOCXtkeXNqYCx9u+T9LuwHeAtwCfB/7R9kOSNijtHw+cY3uKpDWBYQ0hvQsYDewCjAJm1ZIbYFdgB+Bh4GZgb+C3PVzeFEnPlu01gRfL9oeBxbbHSVoLuFnS9cDvgcNtPyFpFHCrpKttu67N04BTbR9crn1iiXdXYAlwj6RvA88BFwD7lXv5qnL+3cC+tl+QdADwFeCIunu/s+3HJX0FmGb72HLvZkr6H9tP11+g7UnAJIC1NtmmPs6IiFgOSVCaZ21Jc8v2TcD3gb2AmbYXlvJ9gG8D2L67fF/BtsATtUYkjSjnXV43oLFWebwZmCzpp8CVpWwGcLqkzYErbd/XENc+wKW2lwJ/kvQbYFzpc6btB0u/c6mmW3pKUCbY7ij124BflvIDgZ0lHVn2RwLbAA8CX5G0H1UysxmwMfDHHvoAmGp7cennTmArYEPgxtq9tP14XV+XlJEjA2vUtXNDXb0DgUMknVr2hwNbAnf1EktERAyCJCjN82xtBKSmJBhPd129W6sBf21sC8D28WVE5SBgtqSxtn8s6bZS9itJH7U9rY99LanbXsrAf38EnGj7umUKq9GQjYCxtv8maRFVYjCYcX0J+LXtw0vSNL3uWP29F3CE7Xv60H9ERAyyrEFpbTcBEwDK1M6WwDIvmLafABZKenepJ0m7lO2tbd9m+/PAo8AWkl4P3G/7W8AvgJ276POosk5kI2A/YOYgX9d1wMckrVG7NknrUo1uPFKSk/FUIyGNngTW60MftwL7SXpd6aM2xTMSeKhsT+wlxhNr62wk7dqHPiMiYpAkQWlt3wFWk9QJXAZMtL2ki3oTgA9LmgfcAdQWdJ5VFpsuAG4B5gHvARaUKZodgR80tHUVML/UnQb8s+3eplj660LgTmBOie17VKMeU4D2cr0fpFov0mg+sLQsfO32Lda2HwWOA64s9+WycuhrwFcl3U7vIy1rAPMl3VH2IyJiiGjZ9YcRMVDt7e3u6OhodhgRESsVSbNttzeWZwQlIiIiWk4WycZykXQV8LqG4s80LoCNiIjojyQosVxsH97sGCIi4u9PpngiIiKi5SRBiYiIiJaTBCUiIiJaThKUiIiIaDlJUCIiIqLlJEGJiIiIlpMEJSIiIlpOPgclYpB0PrSYttOuaXYYfzcWnXlQs0OIiCbKCEpERES0nCQoERER0XKSoKykJJ0t6ZN1+9dJurBu/+uSTuljW9MlveKbJLupe6ykTknzJS2QdGj/o+87SRMlndvD8TeW+OdKukvSpBUZT0REDI2sQVl53Qy8B/impNWAUcD6dcf3Ak7urRFJw/raoaTNgdOBMbYXSxoBbNSvqAfft4Czbf8CQNJOy9ugpGG2ly53ZBERMWAZQVl53QLsWbZ3ABYAT0raUNJawJuAkZJuLyMeF5VyJC2S9B+S5gDvrjUoaTVJkyV9uZs+XwM8CTwFYPsp2wvLudMlnVNGMhZI2q2Ur1v6nlliObSUT5R0paRrJd0n6Wt1cXxI0r2SZgJ793IfNgEerO3Y7ixtDJP0nyWW+ZJOLOVv7cs9kXSgpBmS5ki6vCRjryDpOEkdkjqWPrO4l1AjIqKvkqCspGw/DLwgaUuq0ZIZwG1USUs7cB9wIXCU7Z2oRss+VtfEn22Psf2Tsr86MAW4z/Znu+l2HvAnYKGkiyW9s+H4OrZHA/8PuKiUnQ5Ms70bMB44S9K65dho4ChgJ+AoSVtI2gT4IlVisg+wfS+34mxgmqT/lnSypA1K+XFAGzDa9s7AFEnDgcm93RPgf4DPAgeU/Q6gy+ky25Nst9tuH7bOyF5CjYiIvkqCsnK7hSo5qSUoM+r2HwQW2r631L0E2K/u3Msa2voesMD2v3fXWZn2eBtwJHAvcLakM+qqXFrq3QisX5KFA4HTJM0FpgPDgS1L/am2F9t+DrgT2ArYHZhu+1Hbz3cRZ2NMF1ONFl0O7A/cWkZFDgC+Z/uFUu9x4I19vCd7UCVGN5e4jymxRUTEEEmCsnK7mSoZ2YlqiudWqhGUvaiSgZ483bB/CzC+jDJ0y5WZtr8KvBc4ov5wY3VAwBG2R5efLW3fVY4vqau7lAGuibL9sO2LbB8KvADsOJB2ePmeCLihLubtbX94gG1GRMQAJEFZud0CHAw8bntpGSXYgCpJuQJok/SGUvcDwG96aOv7wK+An0rqMlGQtKmkMXVFo4EH6vaPKvX2ARbbXgxcB5woSeXYrr1c023AmyW9WtIa1K2R6Samt5V6SHot8GrgIeAG4KO1a5H0KuAe+nZPbgX2rtUr62i27SXuiIgYRHkXz8qtk+rdOz9uKBth+0FJHwIuLy/Ss4Dze2rM9jckjQR+KGmC7RcbqqwB/KekTYHngEeB4+uOPyfp9lLv2FL2JeCbwPzybqOFVElVdzH8oUwbzQD+CsztKWaqKaRzJD1X9j9t+4/lLdfbln7/Blxg+9y+3BPbj0qaCFxaW0RLtSbl3sa69XbabCQd+fTTiIhBIbtxVD6i/yRNB0613dHsWJqlvb3dHR2r7OVHRAyIpNm2X/FZXJniiYiIiJaTKZ7okqTbgLUaij9Q+5yRRrb3X8HxnM4r16Nc3tO7jiIiYuWVBCW6ZHv3ZsdQryQiSUYiIlYRmeKJiIiIlpMEJSIiIlpOEpSIiIhoOUlQIiIiouUkQYmIiIiWkwQlIiIiWk7eZhwxSDofWkzbadc0O4xV2qJ81UDE342MoERERETLSYISERERLScJyipM0saSfizpfkmzJc2QdPggtLu/pF8OQjttkp6VNLfuZ83lbbeH/p5aUW1HRET/ZA3KKkqSgJ8Dl9h+XynbCjikCbGsbvuFbg7/n+3RQxpQREQ0XUZQVl1vAZ63fX6twPYDtr8taZiksyTNkjRf0kfhpZGR6ZJ+JuluSVNKooOkt5WyOcC7am1KWlfSRZJmSrpd0qGlfKKkqyVNA6b2J3BJB5bRnjmSLpc0opQvkvTVMtLSIWmMpOsk/Z+k40udEZKmlnM7a/F00cen667/i/26sxERsdySoKy6dgDmdHPsw8Bi2+OAccBHJL2uHNsV+CSwPfB6YG9Jw4ELgHcCY4HX1rV1OjDN9m7AeOAsSeuWY2OAI22/uYc4t66b3jlP0ijgs8ABtscAHcApdfV/V0ZcbgImA0cCewC1JOM54PBy7njg67Ukq0bSgcA2wG7AaGCspP26Ck7ScSUZ6lj6zOIeLiMiIvojUzwBgKTzgH2A54EHgJ0lHVkOj6R6wX4emGn7wXLOXKANeApYaPu+Uv4j4Lhy7oHAIZJOLfvDgS3L9g22H+8ltGWmeCQdTJUc3VzyijWBGXX1ry6PncAI208CT0paImkD4GngKyXheBHYDNgY+GNdGweWn9vL/ohy/Tc2Bmd7EjAJYK1NtnEv1xIREX2UBGXVdQdwRG3H9glldKID+B1wou3r6k+QtD+wpK5oKb3/Dgk4wvY9DW3tTpUs9JeoEpujuzlei+/FhlhfLLFOADYCxtr+m6RFVElTYx9ftf29AcQXERGDIFM8q65pwHBJH6srW6c8Xgd8TNIaAJK2rZuW6crdQJukrct+ffJwHXBi3VqVXZcz7lupppXeUNpbV9K2/Th/JPBISU7GA1t1Uec64Ni6tS2bSXrNcsYdERH9kBGUVZRtSzoMOFvSPwOPUo1ofAa4nGrqZk5JLB4FDuuhreckHQdcI+kZqvUf65XDXwK+CcyXtBqwEDh4OeJ+VNJE4FJJa5XizwL39rGJKcB/SeqkGi26u4s+rpf0JmBGyaueAt4PPDLQuCMion9kZ9o8YjC0t7e7o6Oj2WFERKxUJM223d5YnimeiIiIaDmZ4ommk7QT8MOG4iW2d29GPBER0XxJUKLpbHdSfd5IREQEkCmeiIiIaEFJUCIiIqLlJEGJiIiIlpMEJSIiIlpOEpSIiIhoOUlQIiIiouUkQYmIiIiWk89BiRgknQ8tpu20a5odxipv0ZkHNTuEiBgEGUGJiIiIlpMEJSIiIlpOEpRVlKTTJd0hab6kuZJW2PfeSDpD0qll+98kHTDI7Q/ZtURExNDIGpRVkKQ9gYOBMbaXSBoFrDkUfdv+/GC2tyKuRdLqtl8YlAAjImJAMoKyatoEeMz2EgDbj9l+WNIiSV+T1ClppqQ3AEjaSNIVkmaVn71L+RmSLpI0XdL9kk6qdVBGNe6V9FvgjXXlkyUdWbYXSfqipDmlz+3q+ruhjIpcKOmBknj0+VpKO+Mk3SJpXrme9SQNl3Rx6e92SeNL3YmSrpY0DZgqad1ybTNLvUO76lzScZI6JHUsfWbxcjwlERFRLwnKqul6YIuSQHxH0pvrji22vRNwLvDNUnYOcLbtccARwIV19bcD/hHYDfiCpDUkjQXeS/UNxe8AxvUQy2O2xwDfBU4tZV8AptneAfgZsGV/r0XSmsBlwCds7wIcADwLnAC4XOPRwCWShpe2xgBH2n4zcHqJYTdgPHCWpHUbO7c9yXa77fZh64zsIcyIiOiPTPGsgmw/VZKIfalefC+TdFo5fGnd49ll+wBge0m1JtaXNKJsX1NGL5ZIegTYuLR7le1nACRd3UM4V5bH2cC7yvY+wOEl1msl/WUA1zIb+IPtWaXeEyWWfYBvl7K7JT0AbFuau8H242X7QOCQ2toZYDhVonRXD9cSERGDJAnKKsr2UmA6MF1SJ3BM7VB9tfK4GrCH7efq2ygJy5K6oqX0/3eqdv5AzgW6vZbZA2jq6bptAUfYvmcgMUVExPLJFM8qSNIbJW1TVzQaeKBsH1X3OKNsXw+cWHf+6F66uBE4TNLaktYD3tnPEG8G3lP6OhDYsLuKPVzLPcAmksaVeutJWh24CZhQyralGhXpKgm5DjhRJQuTtGs/ryEiIpZDRlBWTSOAb0vaAHgB+F/gOKp3w2woaT7VyMbRpf5JwHmlfHWqBOT47hq3PUfSZcA84BFgVj/j+yJwqaQPUCVJfwSe7M+12H5e0lHl2NpU608OAL4DfLeMtLwATCzv/mls90tUa3DmS1oNWEh1fyIiYgjIdu+1YpUgaRHQbvuxJsexFrDU9gvlbcTftd3bqE3Ttbe3u6Ojo9lhRESsVCTNtt3eWJ4RlGhFWwI/LSMXzwMfaXI8ERExxJKgxEtstzU7BgDb9wHLrPmQ9GpgahfV32r7z0MSWEREDJkkKLFSKElIy0/zRETE4Mi7eCIiIqLlJEGJiIiIlpMEJSIiIlpOEpSIiIhoOUlQIiIiouUkQYmIiIiWkwQlIiIiWk4+ByVikHQ+tJi2065pdhjRohadeVCzQ4hYqWQEJSIiIlpOEpSIiIhoOUlQoleSTpd0h6T5kuZK2n0F9nWGpFN7OD5Z0sISx1xJJw1Cn7eUxzZJC5a3vYiIWH5ZgxI9krQncDAwxvYSSaOANZsc1qdt/2ywGrO912C1FRERgyMjKNGbTYDHbC8BsP2Y7YclLZL0NUmdkmZKegOApI0kXSFpVvnZu5SfIekiSdMl3V8/8lFGaO6V9Fvgjf0NUNLnS18LJE2SpFI+XdLZkjok3SVpnKQrJd0n6ct15z/VRZs3Shpdt/9bSbt0Ue+40n7H0mcW9zf0iIjoRhKU6M31wBYlgfiOpDfXHVtseyfgXOCbpewc4Gzb44AjgAvr6m8H/COwG/AFSWtIGgu8l+qbit8BjOtDTGfVTfHsBJxre5ztHYG1qUZ8ap633Q6cD/wCOAHYEZgo6dU99PF9YCKApG2B4bbnNVayPcl2u+32YeuM7EPoERHRF0lQoke2nwLGAscBjwKXSZpYDl9a97hn2T4AOFfSXOBqYH1JI8qxa2wvsf0Y8AiwMbAvcJXtZ2w/Uc7pzadtjy4/ncB4SbdJ6gTeAuxQV7fWXidwh+0/lNGg+4EteujjcuBgSWsAxwKT+xBXREQMkqxBiV7ZXgpMB6aXJOCY2qH6auVxNWAP28/Vt1FmXZbUFS1lEH7/JA0HvgO02/69pDOA4XVVan2+2ND/iz31b/sZSTcAhwLvoUrSIiJiiGQEJXok6Y2StqkrGg08ULaPqnucUbavB06sO380PbsROEzS2pLWA97ZzxBrychjZaTmyH6e35MLgW8Bs2z/ZRDbjYiIXmQEJXozAvi2pA2AF4D/pZruORjYUNJ8qpGJo0v9k4DzSvnqVAnI8d01bnuOpMuAeVTTPrP6E5ztv0q6AFgA/LG/5/fS9mxJTwAXD1abERHRN7Lde62IBpIWUU2rPNbsWFYUSZtSTW1tZ/vF3uq3t7e7o6NjhccVEfH3RNLs8maGZWSKJ6ILkj4I3Aac3pfkJCIiBlemeGJAbLetyPYlnQfs3VB8ju0hmW6x/QPgB0PRV0REvFISlGhJtk9odgwREdE8meKJiIiIlpMEJSIiIlpOEpSIiIhoOUlQIiIiouUkQYmIiIiWkwQlIiIiWk4SlIiIiGg5+RyUiEHS+dBi2k67ptlhxN+ZRWce1OwQIpoiIyixUpH0SUnrNDuOiIhYsZKgxMrmk8AKTVAkZWQxIqLJkqBEn0j6uaTZku6QdFwp+7CkeyXNlHSBpHNL+UaSrpA0q/w0fqdOfbsjJF0sqVPSfElHlPLvSuoo/X2xlJ0EbAr8WtKvS9mBkmZImiPpckkjSvk7JN1dYv6WpF+W8leVa5kv6VZJO5fyMyT9UNLNwA8l3ShpdF2cv5W0ywq4tRER0YUkKNFXx9oeC7QDJ0naDPgcsAfVl/ptV1f3HOBs2+OAI4ALe2j3c8Bi2zvZ3hmYVspPL1+/vTPwZkk72/4W8DAw3vZ4SaOAzwIH2B4DdACnSBoOfA94e4l5o7r+vgjcXvr6V5b9QsDtS1tHA98HJgJI2hYYbnten+9WREQslwxlR1+dJOnwsr0F8AHgN7YfB5B0ObBtOX4AsL2k2rnrSxph+6ku2j0AeG9tx/ZfyuZ7ykjN6sAmVMnD/IZz9yjlN5e+1gRmUCVL99teWOpdChxXtvehSpqwPU3SqyWtX45dbfvZsn058DlJnwaOBSZ3dVNKjMcBDFt/o66qRETEACRBiV5J2p8qkdjT9jOSpgN3A2/q5pTVgD1sPzfA/l4HnAqMs/0XSZOB4V1VBW4oIx7154/uom5fPF3bKNd5A3Ao8B5gbFcn2J4ETAJYa5NtPMB+IyKiQaZ4oi9GAn8pL9rbUY1crEs19bJhWVR6RF3964ETazu9JAw3ACfU1d0QWJ8qWVgsaWPg7XX1nwTWK9u3AntLekM5d90yHXMP8HpJbaXeUXXn3wRMKPX3Bx6z/UQ3sV0IfAuYVTeyExERQyAJSvTFtcDqku4CzqRKDB4CvgLMBG4GFgGLS/2TgPayEPVO4Pge2v4ysKGkBZLmUa0vmQfcTjVK8+PSfs0k4FpJv7b9KNU6kUslzadM75Rpmv9X6s2mSmpqsZ0BjC31zwSO6S4w27OBJ4CLe749EREx2GRnVDoGpraupIygXAVcZPuqZscFy8Qm4DzgPttn97ONTYHpVEnPi73VX2uTbbzJMd8cULwR3ckHtcXfO0mzy5silpE1KLE8zpB0ANX6kOuBnzc5nnofkXQM1cLZ26ne1dNnkj4I/DtwSl+SE4CdNhtJR15MIiIGRUZQYkhI+hDwiYbim22f0FX9lVF7e7s7OjqaHUZExEolIyjRVLYvJms5IiKij7JINiIiIlpOEpSIiIhoOUlQIiIiouUkQYmIiIiWkwQlIiIiWk4SlIiIiGg5SVAiIiKi5SRBiYiIiJaTD2qLGCSdDy2m7bRrmh1GrELyPT3x9ywjKBEREdFykqBEREREy0mCEiuUpI0l/VjS/ZJmS5oh6fDlaO8MSacO8Nw2Se8bwHmTJR05kD4jImJgkqDECiNJwM+BG22/3vZY4L3A5g31hmotVBvQ7wQlIiKGXhKUWJHeAjxv+/xage0HbH9b0kRJV0uaBkyVNELSVElzJHVKOrR2jqTTJd0r6bfAG+vKp0tqL9ujJC0q222SbiptzZG0VznlTGBfSXMlnSxpmKSzJM2SNF/SR8v5knSupHsk/Q/wmhV8nyIiokHexRMr0g7AnB6OjwF2tv14GUU53PYTkkYBt0q6utR5LzCa6vd1DjC7l34fAf7B9nOStgEuBdqB04BTbR8MIOk4YLHtcZLWAm6WdD2wK1UitD2wMXAncFFXHZU2jgMYtv5GvYQVERF9lQQlhoyk84B9gOeB84AbbD9eOwx8RdJ+wIvAZlTJwb7AVbafKW1c3Yeu1gDOlTQaWAps2029A4Gd69aXjAS2AfYDLrW9FHi4jPJ0yfYkYBLAWpts4z7EFhERfZAEJVakO4Ajaju2TyijIx2l6Om6uhOAjYCxtv9WpmuG99L+C7w8TVlf92TgT8Au5fhz3Zwv4ETb1y1TKL2jl34jImIFyxqUWJGmAcMlfayubJ1u6o4EHinJyXhgq1J+I3CYpLUlrQe8s+6cRcDYsl3/LpuRwB9svwh8ABhWyp8E1qurdx3wMUlrAEjaVtK6pc+jyhqVTYDxfb7iiIgYFElQYoWxbeAw4M2SFkqaCVwCfKaL6lOAdkmdwAeBu0sbc4DLgHnAfwOz6s75T6oE43ZgVF35d4BjJM0DtuPlkZr5wFJJ8ySdDFxItb5kjqQFwPeoRhWvAu4rx34AzFiuGxEREf2m6jUkIpZXe3u7Ozo6eq8YEREvkTTbdntjeUZQIiIiouUkQYmIiIiWkwQlIiIiWk4SlIiIiGg5SVAiIiKi5SRBiYiIiJaTBCUiIiJaThKUiIiIaDlJUCIiIqLlJEGJiIiIlpNvM44YJJ0PLabttGuaHUasYhadeVCzQ4hYITKCEhERES0nCUpERES0nCQoqwhJSyXNlbRA0uWS1unn+ZdKmi/p5EGK55bBaKehzVGS/ibp+F7qfbL++iX9StIGfa0fERErXhKUVceztkfb3hF4HljmRVxSt+uRJL0WGGd7Z9tnD0YwtvcajHYavBu4FTi6uwqShgGfBF5KOGy/w/Zfe2h3mfoREbHiJUFZNd0EvEHS/pJuknQ1cKek4ZIultQp6XZJ40v964HNygjMvpK2lnStpNnl/O0AJL27jNDMk3RjKdtB0sxy7nxJ25Typ8qjJJ1VzuuUdFQp31/SdEk/k3S3pCmS1Mt1HQ18qsS6ea1Q0lOSvi5pHnA6sCnwa0m/LscXldGXdSVdU+JfIOkoSSc11q8n6ThJHZI6lj6zeGDPRkREvELexbOKKSMlbweuLUVjgB1tL5T0KcC2dypJx/WStgUOAX5pe3RpYypwvO37JO0OfAd4C/B54B9tP1Q3ZXI8cI7tKZLWBIY1hPQuYDSwCzAKmFVLboBdgR2Ah4Gbgb2B33ZzXVsAm9ieKemnwFHA18vhdYHbbH+q1D0WGG/7sYZm3gY8bPugUm+k7cWSTummPrYnAZMA1tpkG3cVW0RE9F9GUFYda0uaC3QAvwO+X8pn2l5YtvcBfgRg+27gAWDb+kYkjQD2Ai4v7X0P2KQcvhmYLOkjvJyIzAD+VdJngK1sP9sQ1z7ApbaX2v4T8BtgXF1sD9p+EZgLtPVwfUcBPy3bP2HZaZ6lwBU9nFvTCfyDpP+QtK/tDIlERDRJRlBWHc/WRkBqyozJ0/1sZzXgr41tAdg+voyoHATMljTW9o8l3VbKfiXpo7an9bGvJXXbS+n59/Vo4LWSJpT9TSVtY/s+4DnbS3vrzPa9ksYA7wC+LGmq7X/rY6wRETGIMoIS9W4CJgCUqZ0tgXvqK9h+Algo6d2lniTtUra3tn2b7c8DjwJbSHo9cL/tbwG/AHbuos+jJA2TtBGwHzCzP0GXWEfY3sx2m+024Kt0v1j2SWC9LtrZFHjG9o+As6imv7qtHxERK04SlKj3HWA1SZ3AZcBE20u6qDcB+HBZdHoHcGgpP6ssdF0A3ALMA94DLCjTQTsCP2ho6ypgfqk7Dfhn23/sZ9xHl3bqXUH3Ccok4NouFr3uBMwssX4B+HIv9SMiYgWRnXV9EYOhvb3dHR0dzQ4jImKlImm27fbG8oygRERERMvJItlYqUi6CnhdQ/FnbF/XjHgiImLFSIISKxXbhzc7hoiIWPEyxRMREREtJwlKREREtJwkKBEREdFykqBEREREy0mCEhERES0nCUpERIFomZYAABG2SURBVES0nCQoERER0XLyOSgRg6TzocW0nXZNs8OIaEmLzjyo2SHESiYjKBEREdFykqBEREREy+k1QZG0VNLcup+25elQ0iGSTivbZ0g6dQBtHCzpdknzJN0p6aOl/HhJH1ye+Or6mCjp0YZr334A7SySNGowYuqhj39dke33laQ2SZZ0Yl3ZuZImDnEcL91zSbcMQnsTJZ27/JFFRERf9WUNyrO2Rw9Wh7avBq4e6PmS1gAmAbvZflDSWkBbafv8QQnyZZfZ/vggt7ki/CvwlaHqTNLqtl/o5vAjwCckfc/284Pcdr/Z3muw2oqIiKHT7ykeSSMkTZU0R1KnpENLeZukuyVNlnSvpCmSDpB0s6T7JO1W6r3ir1FJW0uaU7e/Tf1+g/WoEqs/A9heYvuect4Zkk6VtGnDyMdSSVtJ2kjSFZJmlZ+9B3D9h5frl6RNyrW+ttyXi8s9mS/piD6298FSf56kH5ayyZKOrKvzVHncRNKN5ZoWSNpX0pnA2qVsSql3Sjm+QNInS1lfn591JV0kaWYZpao9vxMlXS1pGjC1h0t6tBw/potrHS3p1nK9V0nasJRPl/RNSR1Uyc10SWdL6pB0l6Rxkq4scX65rr2fS5ot6Q5Jx3Vzf2v37t/qfh8eknRxKX9/uda5kr4naVgp/1C5TzOBbn9PJB1X4uxY+sziHm5LRET0R18SlLXr/mO/CngOONz2GGA88HVJKnXfAHwd2K78vA/YBziV6q/8Ltn+P2CxpNpIzYeAi7up+zjVCMwDki6VNEHSag11HrY9uoz8XABcYfsB4BzgbNvjgCOAC3u59qMaEp21bV8F/AE4obT9Bdt/BD4HLLa9k+2dgWm9tI2kHYDPAm+xvQvwiV5OeR9wXbmuXYC5tk+jjHLZniBpLNX92x3YA/iIpF3L+X15fk4Hptnejer5PUvSuuXYGOBI22/uJc7/AE6tvdjX+QHwmXJ/OoEv1B1b03a77a+X/edttwPnA7+gut87AhMlvbrUOdb2WKAdOKmu/BVsf77ct/2Bx4FzJb0JOArYuxxbCkyQtAnwRarEZB+g26k925NK3O3D1hnZy22JiIi+6vcUj6oplq9I2g94EdgM2LgcXmi7s9S7A5hq25I6KdMwPbgQ+JCkU6heNHbrrqLtf5K0E3AA1YvrPwATG+uVEZKPUL3IUOpv/3I+xfqSRth+qpuuupviORFYANxq+9K6tt9bF+Nfuou/zluAy20/Vs55vJf6s4CLynPwc9tzu6izD3CV7acBJF0J7EuV1PXl+TkQOEQvrw0aDmxZtm/oQ4zYvl/SbVQJEKW/kcAGtn9Tii4BLq877bKGZmrTgJ3AHbb/UNq5H9iCagTtJEmHl3pbANuU8i6VRPpHwDdsz5b0cWAsMKv8TqxNNUW1OzDd9qPlvMuAbXu77oiIGDwD+RyUCcBGwFjbf5O0iOpFDGBJXb0X6/Zf7ENfV1D9RT0NmG272xcagPJC21mmRRbSkKCUv4K/DxxSl4CsBuxh+7leYunN5lTXtLGk1Wy/uJztNXqBMrpVRofWBLB9Y0kMDwImS/qG7R/0o92+PD8CjqhNm9VI2h14uh99fQX4GfCb3ioWjW3Xx9YY9+qS9qdKCve0/Yyk6bz8e9idM4AHbddG5wRcYvtf6itJOqyPMUdExAoykLcZjwQeKcnJeGCrwQikJA3XAd+lm+kdeGkNzP51RaOBBxrqrEH11/lnbN9bd+h6qtGPWr1+L/6VtDpwEXA0cBdwSjl0A9U0RK3ehn1obhrw7trUhKRXlfJFVH/ZAxwCrFGObwX8yfYFVCNOY0qdv5VrBrgJOEzSOmVq5vBS1lfXASfWpu3qpof6xfbdwJ3AO8v+YuAvkvYtVT5A35OXrowE/lKSk+2oprO6JemdVAnNSXXFU4EjJb2m1HlVuce3AW+W9OpyX9+9HHFGRMQADCRBmQK0l2mBDwJ3D2I8U6j+Qr6+hzoC/lnSPZLmUq0VmNhQZy+qdQlfrFs/sinVi1N7WaR5J3B8L/E0rkHZi2qtxk22f0uVnPxTWcvwZWBDVQtT51Gt3+iR7TuAfwd+U875Rjl0AdUL5DxgT14eXdgfmCfpdqppsHNK+SRgvqQptucAk4GZVC+0F9q+vbdY6nyJKiGaX6aBvtSPcxv9O9VoU80xVGta5lMllv+2HG1fSzWSchdwJnBrL/VPoZqOrC2I/Tfbd1KtAbq+xHQDsEmZTjoDmAHcTJWIRkTEEJLtZsfwkrLuYaTtzzU7loj+am9vd0dHR7PDiIhYqUiaXd4UsYyW+S6e8g6hrakWjkZERMQqrGUSFNuHN5aVpOV1DcWfsX3dYPUr6UO88u29N9s+oav6A+zj1XT92SFv7W0xcCsq76D6YUPxEtu7NyOeiIj4+9NSUzwRK7NM8URE9F93Uzz5ssCIiIhoOUlQIiIiouUkQYmIiIiWkwQlIiIiWk4SlIiIiGg5SVAiIiKi5bTM56BErOw6H1pM22nXNDuMiIghtejMg1ZIuxlBiYiIiJaTBCUiIiJaThKUiIiIaDlJUABJZ0v6ZN3+dZIurNv/uqRT+tjWdEmv+MjefsQyUdKmAzjvMEnbD7TfwSDJkr5et3+qpDOGOIaX7r+kX0naYDnb21/SLwcnuoiI6KskKJWbgb0AJK0GjAJ2qDu+F3BLb41IGjYIsUwE+pWgSFodOAxoaoICLAHeJWnUQE4u1zFobL/D9l8Hs82IiBgaSVAqtwB7lu0dgAXAk5I2lLQW8CZgpKTbJXVKuqiUI2mRpP+QNAd4d61BSatJmizpy111KGlYOb6gtHmypCOBdmCKpLmS1pb0eUmzSr1JklTOny7pm5I6gM8AhwBnlfO27qbPj5S25km6QtI6pXxrSbeWOL4s6am6cz5dzpkv6Yu93McXgEnAyV303SZpWmlnqqQtS/lkSedLug34Wtn/bonn/jKCcZGkuyRNrmvvu5I6JN3RXVzluRkl6fhyX+ZKWijp1+X4gZJmSJoj6XJJI0r52yTdXZ7Td/V0wZKOK3F0LH1mcS+3JyIi+ioJCmD7YeCF8qK5FzADuI0qaWkH7gMuBI6yvRPV27M/VtfEn22Psf2Tsr86MAW4z/Znu+l2NLCZ7R1Lmxfb/hnQAUywPdr2s8C5tsfZ3hFYGzi4ro01bbfb/nfgauDT5bz/66bPK0tbuwB3AR8u5ecA55Q4HqxVlnQgsA2wW4l3rKT9uruPxXnABEkjG8q/DVxie+dyb75Vd2xzYC/btWm0Danu/cnlus6mShx3kjS61Dm9fPvlzsCbJe3cXUC2z7c9GhhXru8bZZTns8ABtsdQ3fdTJA0HLgDeCYwFXtvTxdqeVJ6D9mHrNF5yREQMVBKUl91ClZzUEpQZdfsPAgtt31vqXgLUv1Bf1tDW94AFJXHozv3A6yV9W9LbgCe6qTde0m2SOoG3sOzUU2O/vdlR0k2lrQl1be0JXF62f1xX/8DyczswB9iOKmHplu0ngB8AJzUc2rOu7R8C+9Qdu9z20rr9/7JtoBP4k+1O2y8CdwBtpc57ygjH7eU6+jK9dQ4wzfZ/AXuUc26WNBc4BtiqXONC2/eVGH7Uh3YjImKQJUF5WW0dyk5UUzy3Ur2o7gVM7+Xcpxv2b6FKLIZ3d4LtvwC7lLaPpxqhWUY5/zvAkWV04wKgvs3GfnszGfh4aeuLDW11RcBXy6jMaNtvsP39PvTzTarRmXX7GFfjdSwpjy/Wbdf2V5f0OuBU4K1lROYaerkWSROpEpDadJCAG+qubXvbH+62gYiIGFJJUF52C9X0yeO2l9p+HNiAKkm5AmiT9IZS9wPAb3po6/vAr4Cfdrfws0wxrGb7CqqphjHl0JPAemW79qL7WFkfcWQPfdaf1531gD9IWoNqBKXmVuCIsv3euvLrgGPr1mZsJuk1vfRBuXc/5eUpJKjub63tCcBNvbXTg/WpkprFkjYG3t5TZUljqRKa95eRGKiuee/acyppXUnbAndTPde1dTxHL0ecERExQPmo+5d1Ur1758cNZSNsPyjpQ8DlJeGYBZzfU2O2v1HWYfxQ0oS6F8aazYCLy7uGAP6lPE4Gzpf0LFVydAHViM4fS7/d+QlwgaSTqEZculqH8jmqtTWPlsdaQvNJ4EeSTgeuBRaXa7he0puAGWVt7lPA+4FHerr24uvAx+v2TyzX++nS/4f60EaXbM+TdDtVMvF7qtGvnnwceBXw63IdHbb/qYyqXFpb8Ax81va9ko4DrpH0DFUi1VviB8BOm42kYwV95HNExKpG1TR7rMrKu3metW1J7wWOtn1os+Na2bS3t7ujo6PZYURErFQkzS5velhGRlACqnernFvewvxX4NgmxxMREau4JChDoHzGx1oNxR+w3bmC+jsP2Luh+BzbF3dV3/ZNVAt2+9L2q4GpXRx6q+0/9yvQiIiIbiRBGQK2dx/i/k5YgW3/meozUSIiIlaYvIsnIiIiWk4WyUYMEklPAvc0O45ujAIea3YQXWjVuCCxDVRiG5hVObatbG/UWJgpnojBc09XK9FbgaSOVoytVeOCxDZQiW1gEtsrZYonIiIiWk4SlIiIiGg5SVAiBs+kZgfQg1aNrVXjgsQ2UIltYBJbgyySjYiIiJaTEZSIiIhoOUlQIiIiouUkQYlYTpLeJukeSf8r6bRmx1MjaQtJv5Z0p6Q7JH2i2TE1kjRM0u2SftnsWOpJ2kDSzyTdLekuSXs2O6YaSSeX53OBpEslDW9iLBdJekTSgrqyV0m6QdJ95XHDFortrPKczpd0laQNWiW2umOfkmRJo1olLkknlvt2h6SvDVU8SVAiloOkYcB5wNuB7YGjJW3f3Khe8gLwKdvbA3sAJ7RQbDWfAO5qdhBdOAe41vZ2VN9T1RIxStoMOAlot70jMAx4bxNDmgy8raHsNGCq7W2ovrerWUn7ZF4Z2w3AjrZ3Bu4F/mWogyom88rYkLQFcCDwu6EOqJhMQ1ySxgOHArvY3gH4z6EKJglKxPLZDfhf2/fbfh74CdU/5qaz/Qfbc8r2k1Qvsps1N6qXSdocOAi4sNmx1JM0EtgP+D6A7edt/7W5US1jdWBtSasD6wAPNysQ2zcCjzcUHwpcUrYvAQ4b0qCKrmKzfb3tF8rurcDmQx4Y3d43gLOBfwaa8u6VbuL6GHCm7SWlziNDFU8SlIjlsxnw+7r9B2mhJKBGUhuwK3BbcyNZxjep/jN+sdmBNHgd8ChwcZl+ulDSus0OCsD2Q1R/wf4O+AOw2Pb1zY3qFTa2/Yey/Udg42YG04Njgf9udhA1kg4FHrI9r9mxNNgW2FfSbZJ+I2ncUHWcBCXi75ykEcAVwCdtP9HseAAkHQw8Ynt2s2PpwurAGOC7tncFnqZ50xTLKOs5DqVKojYF1pX0/uZG1T1Xn2PRcp9lIel0qinQKc2OBUDSOsC/Ap9vdixdWB14FdU08aeBn0rSUHScBCVi+TwEbFG3v3kpawmS1qBKTqbYvrLZ8dTZGzhE0iKqabG3SPpRc0N6yYPAg7Zro00/o0pYWsEBwELbj9r+G3AlsFeTY2r0J0mbAJTHIZsS6AtJE4GDgQlunQ8C25oq6ZxX/k1sDsyR9NqmRlV5ELjSlZlUI55DsoA3CUrE8pkFbCPpdZLWpFqweHWTYwKg/JXzfeAu299odjz1bP+L7c1tt1Hds2m2W2IkwPYfgd9LemMpeitwZxNDqvc7YA9J65Tn9620yALeOlcDx5TtY4BfNDGWZUh6G9W04iG2n2l2PDW2O22/xnZb+TfxIDCm/C4228+B8QCStgXWZIi+dTkJSsRyKAvuPg5cR/VC8VPbdzQ3qpfsDXyAanRibvl5R7ODWkmcCEyRNB8YDXylyfEAUEZ1fgbMATqp/g9v2kekS7oUmAG8UdKDkj4MnAn8g6T7qEZ8zmyh2M4F1gNuKP8ezm+h2Jqum7guAl5f3nr8E+CYoRp5ykfdR0RERMvJCEpERES0nCQoERER0XKSoERERETLSYISERERLScJSkRERLScJCgRERHRcpKgRERERMv5/0ZdKiPSkXlBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3IBvj3M4y_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red = pd.DataFrame()\n",
        "for i in range(1, 6):\n",
        "    red = pd.concat([red,pd.DataFrame(result[i])],axis=1)\n",
        "red.columns=['1','2','3','4','5']"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw9eVJco5V63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = pd.DataFrame(data=test_df['ID'], index=None)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3uSy3cq5WhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final['Segmentation'] = red.mode(axis=1)[0]"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr0TMCcL5ltX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final['Segmentation'] = final['Segmentation'].map(Segmentation_Mapping_Inverse)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iXfHUm85u0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.to_csv(\"kfold_catboost_v3.csv\",index=False)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ZWBoIX3gh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}